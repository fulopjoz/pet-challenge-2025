{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85634581",
   "metadata": {},
   "source": [
    "# PET Challenge 2025 \u2014 Approach Comparison\n",
    "\n",
    "## Two Scoring Approaches\n",
    "\n",
    "| Aspect | Conservation (MSA + Table S6) | ESM PLM (Zero-Shot) |\n",
    "|--------|-------------------------------|---------------------|\n",
    "| **Method** | Penalize mutations at conserved positions | ESM2 log-likelihood ratio per mutation |\n",
    "| **Compute** | CPU-only, ~1 min (MAFFT) | GPU required, ~30 min (ESM2-650M) |\n",
    "| **Biological prior** | Conservation = function | Evolutionary plausibility |\n",
    "| **Notebook** | `Conservation_Scoring_Pipeline.ipynb` | `PET_Challenge_2025_Pipeline_v2.ipynb` |\n",
    "| **Output** | `results/submission_conservation.csv` | `results/submission_zero_shot_v5.csv` |\n",
    "\n",
    "## Evaluation Strategy\n",
    "\n",
    "Since ground truth is unavailable before the competition deadline, we evaluate using:\n",
    "\n",
    "1. **Inter-approach agreement** \u2014 Spearman/Kendall correlation, top-K overlap, rank-rank plots\n",
    "2. **WT vs mutant separation** \u2014 Cohen's d, Mann-Whitney AUC (WT should score higher on average)\n",
    "3. **IsPETase validation** \u2014 10 single-point mutants with experimental delta-Tm (Son 2019)\n",
    "4. **Score distribution quality** \u2014 entropy, spread, discrimination capacity\n",
    "5. **Ensemble exploration** \u2014 alpha-sweep to find optimal blending\n",
    "\n",
    "**Competition metric:** NDCG (rank-based) \u2014 so rank-order quality is what matters most.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cd0756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "matplotlib.rcParams.update({'font.size': 11, 'figure.dpi': 120})\n",
    "\n",
    "# Paths \u2014 detect project root (works in Colab, VS Code, and local)\n",
    "if os.path.exists('data/petase_challenge_data'):\n",
    "    PROJECT_ROOT = os.getcwd()\n",
    "elif os.path.exists('pet-challenge-2025/data/petase_challenge_data'):\n",
    "    PROJECT_ROOT = os.path.join(os.getcwd(), 'pet-challenge-2025')\n",
    "    os.chdir(PROJECT_ROOT)\n",
    "elif os.path.exists('/content/pet-challenge-2025/data/petase_challenge_data'):\n",
    "    PROJECT_ROOT = '/content/pet-challenge-2025'\n",
    "    os.chdir(PROJECT_ROOT)\n",
    "else:\n",
    "    raise FileNotFoundError(\n",
    "        'Cannot find data/petase_challenge_data/. '\n",
    "        'Run this notebook from the repo root or clone first.'\n",
    "    )\n",
    "DATA_DIR = os.path.join(PROJECT_ROOT, 'data', 'petase_challenge_data')\n",
    "RESULTS_DIR = os.path.join(PROJECT_ROOT, 'results')\n",
    "\n",
    "CONS_CSV = os.path.join(RESULTS_DIR, 'submission_conservation.csv')\n",
    "ESM_CSV  = os.path.join(RESULTS_DIR, 'submission_zero_shot_v5.csv')\n",
    "WT_CSV   = os.path.join(DATA_DIR, 'pet-2025-wildtype-cds.csv')\n",
    "TEST_CSV = os.path.join(DATA_DIR, 'predictive-pet-zero-shot-test-2025.csv')\n",
    "FEAT_CSV = os.path.join(PROJECT_ROOT, 'data', 'features_matrix.csv')\n",
    "MUT_CSV  = os.path.join(PROJECT_ROOT, 'data', 'mutations_dataset.csv')\n",
    "\n",
    "# Target columns (short aliases)\n",
    "TARGETS = {\n",
    "    'act1': 'activity_1 (\\u03bcmol [TPA]/min\\u00b7mg [E])',\n",
    "    'act2': 'activity_2 (\\u03bcmol [TPA]/min\\u00b7mg [E])',\n",
    "    'expr': 'expression (mg/mL)',\n",
    "}\n",
    "TARGET_RANGES = {'act1': (0, 5), 'act2': (0, 5), 'expr': (0, 3)}\n",
    "TARGET_LABELS = {'act1': 'Activity 1 (pH 5.5)', 'act2': 'Activity 2 (pH 9.0)', 'expr': 'Expression'}\n",
    "\n",
    "print(\"Approach Comparison Notebook \u2014 PET Challenge 2025\")\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb8bf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- File existence checks ---\n",
    "cons_available = os.path.exists(CONS_CSV)\n",
    "esm_available  = os.path.exists(ESM_CSV)\n",
    "print(f\"Conservation submission: {'FOUND' if cons_available else 'MISSING'} \u2014 {CONS_CSV}\")\n",
    "print(f\"ESM submission:          {'FOUND' if esm_available else 'MISSING'} \u2014 {ESM_CSV}\")\n",
    "\n",
    "if not cons_available:\n",
    "    raise FileNotFoundError(\"Conservation submission is required. Run Conservation_Scoring_Pipeline first.\")\n",
    "\n",
    "# --- Load submissions ---\n",
    "cons = pd.read_csv(CONS_CSV)\n",
    "print(f\"\\nConservation: {len(cons)} sequences, columns: {list(cons.columns)}\")\n",
    "\n",
    "if esm_available:\n",
    "    esm = pd.read_csv(ESM_CSV)\n",
    "    print(f\"ESM:          {len(esm)} sequences, columns: {list(esm.columns)}\")\n",
    "    # Verify sequence alignment\n",
    "    assert list(cons['sequence']) == list(esm['sequence']), \\\n",
    "        \"Sequence order mismatch between submissions!\"\n",
    "    print(\"Sequence order: MATCHED\")\n",
    "else:\n",
    "    esm = None\n",
    "    print(\"\\nESM submission not found \u2014 comparison cells will show conservation-only analysis.\")\n",
    "    print(\"To enable full comparison, copy submission_zero_shot_v5.csv from Colab to results/\")\n",
    "\n",
    "# --- Load WT sequences for WT/mutant classification ---\n",
    "wt_df = pd.read_csv(WT_CSV)\n",
    "wt_set = set(wt_df['Wt AA Sequence'].values)\n",
    "print(f\"\\nWT scaffolds loaded: {len(wt_set)}\")\n",
    "\n",
    "is_wt = cons['sequence'].isin(wt_set).values\n",
    "n_wt = is_wt.sum()\n",
    "n_mut = (~is_wt).sum()\n",
    "print(f\"Test set: {n_wt} WT sequences, {n_mut} mutant sequences\")\n",
    "print(f\"WT fraction: {n_wt/len(cons)*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e41283b",
   "metadata": {},
   "source": [
    "## 1. Submission-Level Comparison\n",
    "\n",
    "Direct comparison of the two approaches on the 4988 test sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768641bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not esm_available:\n",
    "    print(\"SKIPPING \u2014 ESM submission not available.\")\n",
    "else:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 4.5))\n",
    "    for idx, (key, col) in enumerate(TARGETS.items()):\n",
    "        ax = axes[idx]\n",
    "        c_scores = cons[col].values\n",
    "        e_scores = esm[col].values\n",
    "\n",
    "        # Color by WT/mutant\n",
    "        colors = np.where(is_wt, 'steelblue', 'coral')\n",
    "        ax.scatter(c_scores[~is_wt], e_scores[~is_wt], s=6, alpha=0.15, c='coral', label='Mutant')\n",
    "        ax.scatter(c_scores[is_wt], e_scores[is_wt], s=12, alpha=0.4, c='steelblue', label='WT')\n",
    "\n",
    "        # Diagonal reference\n",
    "        lo, hi = TARGET_RANGES[key]\n",
    "        ax.plot([lo, hi], [lo, hi], 'k--', alpha=0.3, lw=1)\n",
    "\n",
    "        # Statistics\n",
    "        rho, p_rho = stats.spearmanr(c_scores, e_scores)\n",
    "        tau, p_tau = stats.kendalltau(c_scores, e_scores)\n",
    "        ax.set_title(f\"{TARGET_LABELS[key]}\\nSpearman $\\\\rho$={rho:.3f}, Kendall $\\\\tau$={tau:.3f}\", fontsize=11)\n",
    "        ax.set_xlabel('Conservation score')\n",
    "        ax.set_ylabel('ESM score')\n",
    "        ax.legend(fontsize=8, loc='lower right')\n",
    "\n",
    "    plt.suptitle('ESM vs Conservation \u2014 Per-Target Score Comparison', fontsize=13, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, 'comparison_scatter.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"Saved: results/comparison_scatter.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd26df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not esm_available:\n",
    "    print(\"SKIPPING \u2014 ESM submission not available.\")\n",
    "else:\n",
    "    K_values = [20, 50, 100, 200, 500]\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 4.5))\n",
    "\n",
    "    for idx, (key, col) in enumerate(TARGETS.items()):\n",
    "        ax = axes[idx]\n",
    "        c_ranks = stats.rankdata(-cons[col].values)  # rank 1 = highest score\n",
    "        e_ranks = stats.rankdata(-esm[col].values)\n",
    "\n",
    "        shared_counts = []\n",
    "        jaccard_vals = []\n",
    "        for K in K_values:\n",
    "            c_topk = set(np.where(c_ranks <= K)[0])\n",
    "            e_topk = set(np.where(e_ranks <= K)[0])\n",
    "            overlap = len(c_topk & e_topk)\n",
    "            jaccard = overlap / len(c_topk | e_topk) if len(c_topk | e_topk) > 0 else 0\n",
    "            shared_counts.append(overlap)\n",
    "            jaccard_vals.append(jaccard)\n",
    "\n",
    "        x = np.arange(len(K_values))\n",
    "        width = 0.35\n",
    "        ax.bar(x - width/2, shared_counts, width, color='steelblue', edgecolor='white', label='Shared')\n",
    "        ax.bar(x + width/2, [K - s for K, s in zip(K_values, shared_counts)], width,\n",
    "               color='coral', edgecolor='white', label='Unique (each)')\n",
    "\n",
    "        # Annotate Jaccard\n",
    "        for i, (j, k) in enumerate(zip(jaccard_vals, K_values)):\n",
    "            ax.text(i, k * 0.95, f'J={j:.2f}', ha='center', va='top', fontsize=8, fontweight='bold')\n",
    "\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels([f'Top {K}' for K in K_values], fontsize=9)\n",
    "        ax.set_ylabel('Number of sequences')\n",
    "        ax.set_title(TARGET_LABELS[key], fontsize=11)\n",
    "        ax.legend(fontsize=8, loc='upper left')\n",
    "\n",
    "    plt.suptitle('Top-K Overlap Between Approaches', fontsize=13, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, 'comparison_topk_overlap.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"Saved: results/comparison_topk_overlap.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284a8410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohens_d(group1, group2):\n",
    "    # Cohen's d effect size\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    var1, var2 = np.var(group1, ddof=1), np.var(group2, ddof=1)\n",
    "    pooled_std = np.sqrt(((n1 - 1) * var1 + (n2 - 1) * var2) / (n1 + n2 - 2))\n",
    "    return (np.mean(group1) - np.mean(group2)) / pooled_std if pooled_std > 0 else 0\n",
    "\n",
    "def mann_whitney_auc(group1, group2):\n",
    "    # Mann-Whitney U as AUC: P(WT > Mutant)\n",
    "    u, _ = stats.mannwhitneyu(group1, group2, alternative='greater')\n",
    "    return u / (len(group1) * len(group2))\n",
    "\n",
    "approaches = [('Conservation', cons)]\n",
    "if esm_available:\n",
    "    approaches.append(('ESM', esm))\n",
    "\n",
    "n_rows = len(approaches)\n",
    "fig, axes = plt.subplots(n_rows, 3, figsize=(16, 4.5 * n_rows))\n",
    "if n_rows == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "colors_map = {'Conservation': ('steelblue', 'coral'), 'ESM': ('forestgreen', 'darkorange')}\n",
    "sep_stats = []\n",
    "\n",
    "for row_idx, (name, df) in enumerate(approaches):\n",
    "    c_wt, c_mut = colors_map[name]\n",
    "    for col_idx, (key, col) in enumerate(TARGETS.items()):\n",
    "        ax = axes[row_idx, col_idx]\n",
    "        wt_scores = df[col].values[is_wt]\n",
    "        mut_scores = df[col].values[~is_wt]\n",
    "\n",
    "        ax.hist(wt_scores, bins=30, alpha=0.7, color=c_wt, edgecolor='white', label='WT', density=True)\n",
    "        ax.hist(mut_scores, bins=30, alpha=0.5, color=c_mut, edgecolor='white', label='Mutant', density=True)\n",
    "\n",
    "        d = cohens_d(wt_scores, mut_scores)\n",
    "        auc = mann_whitney_auc(wt_scores, mut_scores)\n",
    "        sep_stats.append({'Approach': name, 'Target': TARGET_LABELS[key],\n",
    "                          'Cohen_d': d, 'MW_AUC': auc,\n",
    "                          'WT_mean': np.mean(wt_scores), 'Mut_mean': np.mean(mut_scores)})\n",
    "\n",
    "        ax.set_title(f\"{name} \u2014 {TARGET_LABELS[key]}\\nCohen's d={d:.2f}, AUC={auc:.3f}\", fontsize=10)\n",
    "        ax.set_xlabel('Score')\n",
    "        ax.set_ylabel('Density')\n",
    "        ax.legend(fontsize=8)\n",
    "\n",
    "plt.suptitle('WT vs Mutant Score Separation', fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'comparison_wt_separation.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "sep_df = pd.DataFrame(sep_stats)\n",
    "print(\"\\nWT/Mutant Separation Statistics:\")\n",
    "print(sep_df.to_string(index=False, float_format='%.3f'))\n",
    "print(\"\\nSaved: results/comparison_wt_separation.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63897887",
   "metadata": {},
   "source": [
    "## 2. IsPETase Validation\n",
    "\n",
    "The 10 single-point IsPETase mutants with experimentally measured delta-Tm (Son 2019) provide a small but direct validation set. **Important:** IsPETase is *not* one of the 313 challenge scaffolds, so these mutants are not in the 4988 test set.\n",
    "\n",
    "- **Conservation:** Score each mutant directly via Table S6 frequencies\n",
    "- **ESM (proxy):** LOOCV on the 31-variant features_matrix.csv to estimate ML prediction quality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60da175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table S6 from Buchholz et al. (Proteins, 2022)\n",
    "# {ispetase_position: (consensus_aa, conservation_frequency_pct)}\n",
    "TABLE_S6 = {\n",
    "    32: (\"Y\", 74), 34: (\"R\", 84), 35: (\"G\", 91), 36: (\"P\", 92),\n",
    "    38: (\"P\", 95), 39: (\"T\", 87), 42: (\"S\", 73), 45: (\"A\", 87),\n",
    "    48: (\"G\", 97), 49: (\"P\", 71), 57: (\"V\", 91), 62: (\"G\", 93),\n",
    "    63: (\"F\", 93), 64: (\"G\", 83), 65: (\"G\", 86), 66: (\"G\", 93),\n",
    "    67: (\"T\", 76), 68: (\"I\", 79), 69: (\"Y\", 84), 70: (\"Y\", 91),\n",
    "    71: (\"P\", 98), 72: (\"T\", 85), 74: (\"T\", 81), 76: (\"G\", 90),\n",
    "    77: (\"T\", 84), 78: (\"F\", 74), 79: (\"G\", 90), 80: (\"A\", 77),\n",
    "    85: (\"P\", 99), 86: (\"G\", 100), 88: (\"T\", 76), 92: (\"S\", 70),\n",
    "    96: (\"W\", 93), 98: (\"G\", 89), 99: (\"P\", 82), 100: (\"R\", 81),\n",
    "    101: (\"L\", 81), 102: (\"A\", 97), 103: (\"S\", 96), 105: (\"G\", 99),\n",
    "    106: (\"F\", 97), 107: (\"V\", 96), 108: (\"V\", 94), 111: (\"I\", 84),\n",
    "    113: (\"T\", 96), 118: (\"D\", 98), 120: (\"P\", 87), 122: (\"S\", 71),\n",
    "    123: (\"R\", 99), 124: (\"G\", 73), 126: (\"Q\", 92), 127: (\"L\", 83),\n",
    "    128: (\"L\", 78), 129: (\"A\", 88), 130: (\"A\", 96), 131: (\"L\", 88),\n",
    "    132: (\"D\", 82), 133: (\"Y\", 77), 134: (\"L\", 85), 138: (\"S\", 83),\n",
    "    145: (\"V\", 82), 146: (\"R\", 71), 148: (\"R\", 81), 150: (\"D\", 94),\n",
    "    153: (\"R\", 94), 154: (\"L\", 85), 156: (\"V\", 89), 158: (\"G\", 100),\n",
    "    159: (\"H\", 87), 160: (\"S\", 100), 161: (\"M\", 94), 162: (\"G\", 100),\n",
    "    163: (\"G\", 99), 164: (\"G\", 96), 165: (\"G\", 97), 167: (\"L\", 88),\n",
    "    169: (\"A\", 89), 170: (\"A\", 82), 173: (\"R\", 76), 174: (\"P\", 76),\n",
    "    176: (\"L\", 84), 178: (\"A\", 95), 179: (\"A\", 78), 181: (\"P\", 80),\n",
    "    182: (\"L\", 79), 184: (\"P\", 76), 185: (\"W\", 77), 197: (\"P\", 97),\n",
    "    198: (\"T\", 93), 202: (\"G\", 75), 206: (\"D\", 100), 209: (\"A\", 87),\n",
    "    211: (\"V\", 70), 214: (\"H\", 77), 217: (\"P\", 79), 218: (\"F\", 74),\n",
    "    219: (\"Y\", 96), 221: (\"S\", 70), 228: (\"A\", 77), 229: (\"Y\", 83),\n",
    "    231: (\"E\", 91), 232: (\"L\", 76), 235: (\"A\", 76), 237: (\"H\", 100),\n",
    "    240: (\"P\", 74), 244: (\"N\", 74), 257: (\"W\", 90), 258: (\"L\", 80),\n",
    "    259: (\"K\", 94), 260: (\"R\", 78), 261: (\"F\", 79), 263: (\"D\", 94),\n",
    "    265: (\"D\", 97), 266: (\"T\", 76), 267: (\"R\", 96), 268: (\"Y\", 92),\n",
    "    270: (\"Q\", 77), 271: (\"F\", 96), 272: (\"L\", 86), 273: (\"C\", 95),\n",
    "    274: (\"P\", 82),\n",
    "}\n",
    "\n",
    "# Load mutations dataset \u2014 filter single-point IsPETase mutants\n",
    "mut_df = pd.read_csv(MUT_CSV)\n",
    "features_df = pd.read_csv(FEAT_CSV)\n",
    "\n",
    "# Single-point mutants: N_mutations == 1 in features_matrix\n",
    "single_mask = features_df['N_mutations'] == 1\n",
    "single_variants = features_df.loc[single_mask, 'variant_name'].values\n",
    "single_df = mut_df[mut_df['variant_name'].isin(single_variants)].copy()\n",
    "print(f\"Single-point IsPETase mutants: {len(single_df)}\")\n",
    "print(f\"Variants: {list(single_df['variant_name'].values)}\")\n",
    "\n",
    "# Parse mutation: e.g. \"D186H\" -> (pos=186, wt_aa='D', mut_aa='H')\n",
    "def parse_single_mutation(mut_str):\n",
    "    wt_aa = mut_str[0]\n",
    "    mut_aa = mut_str[-1]\n",
    "    pos = int(mut_str[1:-1])\n",
    "    return pos, wt_aa, mut_aa\n",
    "\n",
    "# Conservation score for each mutant\n",
    "cons_scores = []\n",
    "for _, row in single_df.iterrows():\n",
    "    pos, wt_aa, mut_aa = parse_single_mutation(row['mutation'])\n",
    "    if pos in TABLE_S6:\n",
    "        consensus_aa, freq_pct = TABLE_S6[pos]\n",
    "        # Penalty: frequency of consensus (WT) minus estimated frequency of mutant\n",
    "        # If WT matches consensus, use table freq; otherwise estimate lower\n",
    "        wt_freq = freq_pct / 100.0 if wt_aa == consensus_aa else (100 - freq_pct) / (19 * 100.0)\n",
    "        mut_freq = freq_pct / 100.0 if mut_aa == consensus_aa else (100 - freq_pct) / (19 * 100.0)\n",
    "        score = -(wt_freq - mut_freq)  # negative penalty = less damage to function\n",
    "    else:\n",
    "        # Position not conserved (< 70%) \u2014 mutation has minimal predicted impact\n",
    "        score = 0.0\n",
    "    cons_scores.append(score)\n",
    "\n",
    "single_df = single_df.copy()\n",
    "single_df['cons_score'] = cons_scores\n",
    "single_df['delta_tm'] = single_df['delta_tm'].astype(float)\n",
    "\n",
    "# Print table\n",
    "print(\"\\n--- IsPETase Single-Point Mutant Validation ---\")\n",
    "print(f\"{'Mutation':<12} {'Pos':>4} {'In S6?':>6} {'Cons Score':>10} {'delta-Tm':>9}\")\n",
    "print(\"-\" * 50)\n",
    "for _, row in single_df.iterrows():\n",
    "    pos, wt_aa, mut_aa = parse_single_mutation(row['mutation'])\n",
    "    in_s6 = 'Yes' if pos in TABLE_S6 else 'No'\n",
    "    print(f\"{row['mutation']:<12} {pos:>4} {in_s6:>6} {row['cons_score']:>10.4f} {row['delta_tm']:>9.2f}\")\n",
    "\n",
    "# Spearman correlation\n",
    "rho, pval = stats.spearmanr(single_df['cons_score'], single_df['delta_tm'])\n",
    "print(f\"\\nSpearman rho = {rho:.3f}, p = {pval:.4f}\")\n",
    "print(f\"(Positive rho means: higher conservation score ~ higher delta-Tm \u2014 correct direction)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64141ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "# --- ML LOOCV on features_matrix (proxy for ESM prediction quality) ---\n",
    "feat_df = pd.read_csv(FEAT_CSV)\n",
    "feature_cols = [c for c in feat_df.columns if c not in ('variant_name', 'Tm')]\n",
    "X = feat_df[feature_cols].values\n",
    "y = feat_df['Tm'].values\n",
    "names = feat_df['variant_name'].values\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "scaler = StandardScaler()\n",
    "y_pred_loocv = np.zeros(len(y))\n",
    "\n",
    "for train_idx, test_idx in loo.split(X):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train = y[train_idx]\n",
    "    X_train_s = scaler.fit_transform(X_train)\n",
    "    X_test_s = scaler.transform(X_test)\n",
    "    model = Ridge(alpha=10.0)\n",
    "    model.fit(X_train_s, y_train)\n",
    "    y_pred_loocv[test_idx] = model.predict(X_test_s)\n",
    "\n",
    "ml_rho, ml_pval = stats.spearmanr(y, y_pred_loocv)\n",
    "ml_rmse = np.sqrt(np.mean((y - y_pred_loocv) ** 2))\n",
    "print(f\"ML LOOCV (Ridge alpha=10, {len(y)} variants):\")\n",
    "print(f\"  Spearman rho = {ml_rho:.3f}, p = {ml_pval:.6f}\")\n",
    "print(f\"  RMSE = {ml_rmse:.2f} C\")\n",
    "\n",
    "# --- Side-by-side validation plot ---\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Conservation score vs delta-Tm (single-point mutants)\n",
    "ax1.scatter(single_df['cons_score'], single_df['delta_tm'],\n",
    "            s=80, c='steelblue', edgecolors='white', zorder=5, linewidths=0.5)\n",
    "for _, row in single_df.iterrows():\n",
    "    ax1.annotate(row['mutation'], (row['cons_score'], row['delta_tm']),\n",
    "                 fontsize=8, xytext=(6, 4), textcoords='offset points')\n",
    "\n",
    "rho_cons, p_cons = stats.spearmanr(single_df['cons_score'], single_df['delta_tm'])\n",
    "ax1.set_xlabel('Conservation Score')\n",
    "ax1.set_ylabel('$\\\\Delta T_m$ ($\\\\degree$C)')\n",
    "ax1.set_title(f'Conservation vs $\\\\Delta T_m$\\nSpearman $\\\\rho$ = {rho_cons:.3f} (p = {p_cons:.3f})', fontsize=11)\n",
    "ax1.axhline(0, ls='--', color='gray', alpha=0.4)\n",
    "ax1.axvline(0, ls='--', color='gray', alpha=0.4)\n",
    "legend1 = [Line2D([0], [0], marker='o', color='w', markerfacecolor='steelblue',\n",
    "                  markersize=8, label=f'n = {len(single_df)} mutants')]\n",
    "ax1.legend(handles=legend1, fontsize=8, loc='lower right')\n",
    "\n",
    "# Right: ML predicted Tm vs actual Tm (LOOCV, all 31 variants)\n",
    "ax2.scatter(y, y_pred_loocv, s=60, c='forestgreen', edgecolors='white', zorder=5, linewidths=0.5)\n",
    "lims = [min(y.min(), y_pred_loocv.min()) - 2, max(y.max(), y_pred_loocv.max()) + 2]\n",
    "ax2.plot(lims, lims, 'r--', alpha=0.5, lw=1.5, label='Perfect prediction')\n",
    "ax2.set_xlim(lims)\n",
    "ax2.set_ylim(lims)\n",
    "ax2.set_xlabel('Actual $T_m$ ($\\\\degree$C)')\n",
    "ax2.set_ylabel('Predicted $T_m$ ($\\\\degree$C, LOOCV)')\n",
    "ax2.set_title(f'ML LOOCV: Ridge on Features Matrix\\n$\\\\rho$ = {ml_rho:.3f}, RMSE = {ml_rmse:.1f}$\\\\degree$C', fontsize=11)\n",
    "legend2 = [Line2D([0], [0], marker='o', color='w', markerfacecolor='forestgreen',\n",
    "                  markersize=8, label=f'n = {len(y)} variants'),\n",
    "           Line2D([0], [0], ls='--', color='r', alpha=0.5, label='y = x')]\n",
    "ax2.legend(handles=legend2, fontsize=8, loc='lower right')\n",
    "\n",
    "plt.suptitle('IsPETase Validation \u2014 Conservation (direct) vs ML Feature Proxy', fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'comparison_ispetase_validation.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: results/comparison_ispetase_validation.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c045f93b",
   "metadata": {},
   "source": [
    "## 3. Score Distribution Analysis\n",
    "\n",
    "Compare how each approach distributes scores across the 4988 test sequences.\n",
    "Good ranking requires spread (not all scores clustered together) and discrimination\n",
    "(different sequences get distinguishably different scores).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78a8dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "approaches_avail = [('Conservation', cons, 'steelblue')]\n",
    "if esm_available:\n",
    "    approaches_avail.append(('ESM', esm, 'forestgreen'))\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 9))\n",
    "\n",
    "entropy_stats = []\n",
    "for col_idx, (key, col) in enumerate(TARGETS.items()):\n",
    "    ax_top = axes[0, col_idx]\n",
    "    ax_bot = axes[1, col_idx]\n",
    "\n",
    "    for name, df, color in approaches_avail:\n",
    "        scores = df[col].values\n",
    "\n",
    "        # Top row: overlaid histograms / KDE\n",
    "        ax_top.hist(scores, bins=50, alpha=0.5, color=color, edgecolor='white',\n",
    "                    density=True, label=name)\n",
    "\n",
    "        # Ranking entropy: how uniformly spread are the ranks?\n",
    "        ranks = stats.rankdata(scores)\n",
    "        norm_ranks = ranks / len(ranks)\n",
    "        # Bin into 50 bins and compute entropy\n",
    "        hist_counts, _ = np.histogram(norm_ranks, bins=50, range=(0, 1))\n",
    "        hist_probs = hist_counts / hist_counts.sum()\n",
    "        hist_probs = hist_probs[hist_probs > 0]\n",
    "        rank_entropy = stats.entropy(hist_probs) / np.log(50)  # normalize to [0, 1]\n",
    "        n_unique = len(np.unique(scores))\n",
    "        entropy_stats.append({'Approach': name, 'Target': TARGET_LABELS[key],\n",
    "                              'Rank Entropy': rank_entropy, 'Unique Scores': n_unique,\n",
    "                              'Std': np.std(scores), 'IQR': np.percentile(scores, 75) - np.percentile(scores, 25)})\n",
    "\n",
    "    ax_top.set_title(TARGET_LABELS[key], fontsize=11)\n",
    "    ax_top.set_xlabel('Score')\n",
    "    ax_top.set_ylabel('Density')\n",
    "    ax_top.legend(fontsize=8)\n",
    "\n",
    "    # Bottom row: rank-rank percentile plots\n",
    "    if esm_available:\n",
    "        c_pctile = stats.rankdata(cons[col].values) / len(cons) * 100\n",
    "        e_pctile = stats.rankdata(esm[col].values) / len(esm) * 100\n",
    "        ax_bot.scatter(c_pctile, e_pctile, s=3, alpha=0.15, c='gray')\n",
    "        ax_bot.plot([0, 100], [0, 100], 'r--', alpha=0.5, lw=1)\n",
    "        rho_rr, _ = stats.spearmanr(c_pctile, e_pctile)\n",
    "        ax_bot.set_title(f'Rank-Rank ($\\\\rho$ = {rho_rr:.3f})', fontsize=10)\n",
    "        ax_bot.set_xlabel('Conservation percentile')\n",
    "        ax_bot.set_ylabel('ESM percentile')\n",
    "        legend_rr = [Line2D([0], [0], ls='--', color='r', alpha=0.5, label='y = x'),\n",
    "                     Line2D([0], [0], marker='o', color='w', markerfacecolor='gray',\n",
    "                            markersize=5, label=f'n = {len(cons)}')]\n",
    "        ax_bot.legend(handles=legend_rr, fontsize=8, loc='lower right')\n",
    "    else:\n",
    "        ax_bot.text(0.5, 0.5, 'ESM not available', ha='center', va='center',\n",
    "                    transform=ax_bot.transAxes, fontsize=12, color='gray')\n",
    "        ax_bot.set_axis_off()\n",
    "\n",
    "plt.suptitle('Score Distributions and Rank Agreement', fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'comparison_distributions.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "ent_df = pd.DataFrame(entropy_stats)\n",
    "print(\"\\nDistribution Statistics:\")\n",
    "print(ent_df.to_string(index=False, float_format='%.4f'))\n",
    "print(\"\\nRank entropy = 1.0 means perfectly uniform rank distribution (ideal).\")\n",
    "print(\"Saved: results/comparison_distributions.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5931fa8d",
   "metadata": {},
   "source": [
    "## 4. Ensemble Exploration\n",
    "\n",
    "Blend Conservation and ESM scores:\n",
    "**ensemble = alpha * Conservation_rank + (1 - alpha) * ESM_rank**\n",
    "\n",
    "Sweep alpha from 0 (pure ESM) to 1 (pure Conservation) in 51 steps.\n",
    "Evaluate WT/mutant separation (Cohen's d) and ranking entropy at each alpha.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f383b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not esm_available:\n",
    "    print(\"SKIPPING \u2014 ESM submission not available for ensemble exploration.\")\n",
    "else:\n",
    "    alphas = np.linspace(0, 1, 51)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(16, 9))\n",
    "    optimal_alphas = {}\n",
    "\n",
    "    for col_idx, (key, col) in enumerate(TARGETS.items()):\n",
    "        c_ranks = stats.rankdata(cons[col].values)\n",
    "        e_ranks = stats.rankdata(esm[col].values)\n",
    "        c_norm = c_ranks / len(c_ranks)\n",
    "        e_norm = e_ranks / len(e_ranks)\n",
    "\n",
    "        d_vals = []\n",
    "        ent_vals = []\n",
    "        for alpha in alphas:\n",
    "            blend = alpha * c_norm + (1 - alpha) * e_norm\n",
    "            wt_blend = blend[is_wt]\n",
    "            mut_blend = blend[~is_wt]\n",
    "            d = cohens_d(wt_blend, mut_blend)\n",
    "            d_vals.append(d)\n",
    "\n",
    "            # Rank entropy of blended scores\n",
    "            blend_ranks = stats.rankdata(blend)\n",
    "            norm_br = blend_ranks / len(blend_ranks)\n",
    "            hist_c, _ = np.histogram(norm_br, bins=50, range=(0, 1))\n",
    "            hist_p = hist_c / hist_c.sum()\n",
    "            hist_p = hist_p[hist_p > 0]\n",
    "            ent_vals.append(stats.entropy(hist_p) / np.log(50))\n",
    "\n",
    "        d_vals = np.array(d_vals)\n",
    "        ent_vals = np.array(ent_vals)\n",
    "\n",
    "        # Optimal alpha: maximize |Cohen's d|\n",
    "        best_idx = np.argmax(np.abs(d_vals))\n",
    "        optimal_alphas[key] = alphas[best_idx]\n",
    "\n",
    "        # Top row: Cohen's d vs alpha\n",
    "        ax_d = axes[0, col_idx]\n",
    "        ax_d.plot(alphas, d_vals, 'b-', lw=2, label=\"Cohen's d\")\n",
    "        ax_d.axvline(alphas[best_idx], ls='--', color='red', alpha=0.7,\n",
    "                     label=f'Optimal $\\\\alpha$={alphas[best_idx]:.2f}')\n",
    "        ax_d.set_xlabel('$\\\\alpha$ (Conservation weight)')\n",
    "        ax_d.set_ylabel(\"Cohen's d (WT vs Mutant)\")\n",
    "        ax_d.set_title(TARGET_LABELS[key], fontsize=11)\n",
    "        ax_d.legend(fontsize=8)\n",
    "\n",
    "        # Bottom row: Rank entropy vs alpha\n",
    "        ax_e = axes[1, col_idx]\n",
    "        ax_e.plot(alphas, ent_vals, 'g-', lw=2, label='Rank entropy')\n",
    "        ax_e.axvline(alphas[best_idx], ls='--', color='red', alpha=0.7,\n",
    "                     label=f'Optimal $\\\\alpha$={alphas[best_idx]:.2f}')\n",
    "        ax_e.set_xlabel('$\\\\alpha$ (Conservation weight)')\n",
    "        ax_e.set_ylabel('Normalized rank entropy')\n",
    "        ax_e.set_title(TARGET_LABELS[key], fontsize=11)\n",
    "        ax_e.legend(fontsize=8)\n",
    "\n",
    "    plt.suptitle('Ensemble Alpha Sweep \u2014 WT/Mutant Separation vs Ranking Quality',\n",
    "                 fontsize=13, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, 'comparison_ensemble_sweep.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nOptimal alpha per target (maximizes |Cohen's d|):\")\n",
    "    for key, alpha in optimal_alphas.items():\n",
    "        print(f\"  {TARGET_LABELS[key]}: alpha = {alpha:.2f}\")\n",
    "    print(\"\\nSaved: results/comparison_ensemble_sweep.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f4257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not esm_available:\n",
    "    print(\"SKIPPING \u2014 ESM submission not available.\")\n",
    "else:\n",
    "    # Generate ensembles\n",
    "    ensemble_50 = cons.copy()\n",
    "    ensemble_opt = cons.copy()\n",
    "\n",
    "    corr_data = {}\n",
    "    for key, col in TARGETS.items():\n",
    "        c_ranks = stats.rankdata(cons[col].values)\n",
    "        e_ranks = stats.rankdata(esm[col].values)\n",
    "        c_norm = c_ranks / len(c_ranks)\n",
    "        e_norm = e_ranks / len(e_ranks)\n",
    "\n",
    "        # alpha = 0.5 ensemble\n",
    "        blend_50 = 0.5 * c_norm + 0.5 * e_norm\n",
    "        lo, hi = TARGET_RANGES[key]\n",
    "        ensemble_50[col] = lo + (stats.rankdata(blend_50) - 1) / (len(blend_50) - 1) * (hi - lo)\n",
    "\n",
    "        # Per-target optimal alpha\n",
    "        alpha_opt = optimal_alphas[key]\n",
    "        blend_opt = alpha_opt * c_norm + (1 - alpha_opt) * e_norm\n",
    "        ensemble_opt[col] = lo + (stats.rankdata(blend_opt) - 1) / (len(blend_opt) - 1) * (hi - lo)\n",
    "\n",
    "        # Spearman between all pairs\n",
    "        corr_data[key] = {\n",
    "            'Conservation': cons[col].values,\n",
    "            'ESM': esm[col].values,\n",
    "            'Ensemble_50': ensemble_50[col].values,\n",
    "        }\n",
    "\n",
    "    # Print correlation matrix per target\n",
    "    print(\"Inter-Approach Spearman Correlation:\\n\")\n",
    "    for key in TARGETS:\n",
    "        data = corr_data[key]\n",
    "        names_c = list(data.keys())\n",
    "        n = len(names_c)\n",
    "        matrix = np.ones((n, n))\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                rho, _ = stats.spearmanr(data[names_c[i]], data[names_c[j]])\n",
    "                matrix[i, j] = rho\n",
    "                matrix[j, i] = rho\n",
    "        corr_df = pd.DataFrame(matrix, index=names_c, columns=names_c)\n",
    "        print(f\"--- {TARGET_LABELS[key]} ---\")\n",
    "        print(corr_df.to_string(float_format='%.3f'))\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead76ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [('act1', 'act2'), ('act1', 'expr'), ('act2', 'expr')]\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4.5))\n",
    "\n",
    "for idx, (k1, k2) in enumerate(pairs):\n",
    "    ax = axes[idx]\n",
    "    col1, col2 = TARGETS[k1], TARGETS[k2]\n",
    "\n",
    "    # Conservation\n",
    "    c1, c2 = cons[col1].values, cons[col2].values\n",
    "    ax.scatter(c1, c2, s=4, alpha=0.12, c='steelblue', label='Conservation')\n",
    "\n",
    "    if esm_available:\n",
    "        e1, e2 = esm[col1].values, esm[col2].values\n",
    "        ax.scatter(e1, e2, s=4, alpha=0.12, c='forestgreen', label='ESM')\n",
    "\n",
    "    # Spearman annotations\n",
    "    rho_c, _ = stats.spearmanr(c1, c2)\n",
    "    text = f\"Cons $\\\\rho$={rho_c:.3f}\"\n",
    "    if esm_available:\n",
    "        rho_e, _ = stats.spearmanr(e1, e2)\n",
    "        text += f\"\\nESM $\\\\rho$={rho_e:.3f}\"\n",
    "\n",
    "    ax.text(0.03, 0.97, text, transform=ax.transAxes, fontsize=9, va='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "    ax.set_xlabel(TARGET_LABELS[k1])\n",
    "    ax.set_ylabel(TARGET_LABELS[k2])\n",
    "    ax.set_title(f'{TARGET_LABELS[k1]} vs {TARGET_LABELS[k2]}', fontsize=10)\n",
    "\n",
    "    legend_elems = [Line2D([0], [0], marker='o', color='w', markerfacecolor='steelblue',\n",
    "                           markersize=6, label='Conservation')]\n",
    "    if esm_available:\n",
    "        legend_elems.append(Line2D([0], [0], marker='o', color='w', markerfacecolor='forestgreen',\n",
    "                                   markersize=6, label='ESM'))\n",
    "    ax.legend(handles=legend_elems, fontsize=8, loc='lower right')\n",
    "\n",
    "plt.suptitle('Cross-Target Consistency', fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'comparison_cross_target.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: results/comparison_cross_target.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e62b95",
   "metadata": {},
   "source": [
    "## 5. Summary and Recommendation\n",
    "\n",
    "Aggregate all metrics into a winner-per-criterion table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac4ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_rows = []\n",
    "\n",
    "# Criterion 1: IsPETase validation (Conservation direct)\n",
    "summary_rows.append({\n",
    "    'Criterion': 'IsPETase delta-Tm correlation',\n",
    "    'Conservation': f'rho={rho_cons:.3f} (direct, n={len(single_df)})',\n",
    "    'ESM (proxy)': f'rho={ml_rho:.3f} (LOOCV Ridge, n={len(y)})',\n",
    "    'Winner': 'Conservation' if abs(rho_cons) > abs(ml_rho) else 'ESM proxy'\n",
    "})\n",
    "\n",
    "# Criterion 2: WT/mutant separation (average Cohen's d)\n",
    "if esm_available:\n",
    "    cons_d_avg = sep_df[sep_df['Approach'] == 'Conservation']['Cohen_d'].abs().mean()\n",
    "    esm_d_avg = sep_df[sep_df['Approach'] == 'ESM']['Cohen_d'].abs().mean()\n",
    "    summary_rows.append({\n",
    "        'Criterion': 'WT/Mutant separation (avg |d|)',\n",
    "        'Conservation': f'{cons_d_avg:.3f}',\n",
    "        'ESM (proxy)': f'{esm_d_avg:.3f}',\n",
    "        'Winner': 'Conservation' if cons_d_avg > esm_d_avg else 'ESM'\n",
    "    })\n",
    "else:\n",
    "    cons_d_avg = sep_df[sep_df['Approach'] == 'Conservation']['Cohen_d'].abs().mean()\n",
    "    summary_rows.append({\n",
    "        'Criterion': 'WT/Mutant separation (avg |d|)',\n",
    "        'Conservation': f'{cons_d_avg:.3f}',\n",
    "        'ESM (proxy)': 'N/A',\n",
    "        'Winner': 'Conservation (only available)'\n",
    "    })\n",
    "\n",
    "# Criterion 3: Ranking entropy (higher = better discrimination)\n",
    "cons_ent = ent_df[ent_df['Approach'] == 'Conservation']['Rank Entropy'].mean()\n",
    "if esm_available:\n",
    "    esm_ent = ent_df[ent_df['Approach'] == 'ESM']['Rank Entropy'].mean()\n",
    "    summary_rows.append({\n",
    "        'Criterion': 'Ranking entropy (avg)',\n",
    "        'Conservation': f'{cons_ent:.4f}',\n",
    "        'ESM (proxy)': f'{esm_ent:.4f}',\n",
    "        'Winner': 'Conservation' if cons_ent > esm_ent else 'ESM'\n",
    "    })\n",
    "else:\n",
    "    summary_rows.append({\n",
    "        'Criterion': 'Ranking entropy (avg)',\n",
    "        'Conservation': f'{cons_ent:.4f}',\n",
    "        'ESM (proxy)': 'N/A',\n",
    "        'Winner': 'Conservation (only available)'\n",
    "    })\n",
    "\n",
    "# Criterion 4: Compute cost\n",
    "summary_rows.append({\n",
    "    'Criterion': 'Compute requirements',\n",
    "    'Conservation': 'CPU, ~1 min',\n",
    "    'ESM (proxy)': 'GPU (A100), ~30 min',\n",
    "    'Winner': 'Conservation'\n",
    "})\n",
    "\n",
    "# Criterion 5: Biological interpretability\n",
    "summary_rows.append({\n",
    "    'Criterion': 'Interpretability',\n",
    "    'Conservation': 'High (per-position conservation)',\n",
    "    'ESM (proxy)': 'Medium (log-likelihood ratios)',\n",
    "    'Winner': 'Conservation'\n",
    "})\n",
    "\n",
    "summary = pd.DataFrame(summary_rows)\n",
    "print(\"=\" * 80)\n",
    "print(\"APPROACH COMPARISON SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "# Count wins\n",
    "cons_wins = sum(1 for r in summary_rows if 'Conservation' in r['Winner'] and 'ESM' not in r['Winner'])\n",
    "esm_wins = sum(1 for r in summary_rows if 'ESM' in r['Winner'] and 'Conservation' not in r['Winner'])\n",
    "ties = len(summary_rows) - cons_wins - esm_wins\n",
    "\n",
    "print(f\"\\n--- Score: Conservation {cons_wins}, ESM {esm_wins}, Ties/N/A {ties} ---\\n\")\n",
    "\n",
    "if cons_wins > esm_wins:\n",
    "    rec = \"Conservation\"\n",
    "    reason = (\"Conservation scoring wins on more criteria. It provides direct biological \"\n",
    "              \"interpretability, requires no GPU, and correlates with experimental delta-Tm data. \"\n",
    "              \"Recommended as primary submission.\")\n",
    "elif esm_wins > cons_wins:\n",
    "    rec = \"ESM\"\n",
    "    reason = (\"ESM scoring wins on more criteria, likely providing better ranking through \"\n",
    "              \"evolutionary plausibility signals captured by the protein language model.\")\n",
    "else:\n",
    "    rec = \"Ensemble or Conservation\"\n",
    "    reason = (\"Results are mixed. Consider submitting Conservation as the safer choice \"\n",
    "              \"(interpretable, validated) or an ensemble at alpha=0.5 for potential synergy.\")\n",
    "\n",
    "print(f\"RECOMMENDATION: Submit **{rec}**\")\n",
    "print(f\"Rationale: {reason}\")\n",
    "\n",
    "if esm_available:\n",
    "    print(f\"\\nIf ensemble is desired, per-target optimal alphas:\")\n",
    "    for key, alpha in optimal_alphas.items():\n",
    "        print(f\"  {TARGET_LABELS[key]}: alpha = {alpha:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}