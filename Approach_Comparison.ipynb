{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85634581",
   "metadata": {
    "id": "85634581"
   },
   "source": [
    "# PET Challenge 2025 — Approach Comparison\n",
    "\n",
    "## Two Scoring Approaches\n",
    "\n",
    "| Aspect | Conservation (MSA + Table S6) | ESM PLM (Zero-Shot) |\n",
    "|--------|-------------------------------|---------------------|\n",
    "| **Method** | Penalize mutations at conserved positions | ESM2 log-likelihood ratio per mutation |\n",
    "| **Compute** | CPU-only, ~1 min (MAFFT) | GPU required, ~30 min (ESM2-650M) |\n",
    "| **Biological prior** | Conservation = function | Evolutionary plausibility |\n",
    "| **Notebook** | `Conservation_Scoring_Pipeline.ipynb` | `PET_Challenge_2025_Pipeline_v2.ipynb` |\n",
    "| **Output** | `results/submission_conservation.csv` | `results/submission_zero_shot_v5.csv` |\n",
    "\n",
    "## Evaluation Strategy\n",
    "\n",
    "Since ground truth is unavailable before the competition deadline, we evaluate using:\n",
    "\n",
    "1. **Inter-approach agreement** — Spearman/Kendall correlation, top-K overlap, rank-rank plots\n",
    "2. **WT vs mutant separation** — Cohen's d, Mann-Whitney AUC (WT should score higher on average)\n",
    "3. **IsPETase validation** — 10 single-point mutants with experimental delta-Tm (Son 2019)\n",
    "4. **Score distribution & granularity** — entropy, unique scores, tie-rate (critical for NDCG)\n",
    "5. **Within-scaffold discrimination** — score variance among mutants of the same WT\n",
    "6. **Ensemble exploration** — alpha-sweep to find optimal blending\n",
    "\n",
    "**Competition metric:** NDCG (rank-based) — rank-order quality is what matters most. Tied scores are penalized by NDCG (random tie-breaking degrades ranking quality).\n",
    "\n",
    "### Methodological Notes\n",
    "\n",
    "- **IsPETase is NOT one of the 313 challenge scaffolds**, so ESM2 zero-shot scores are unavailable for IsPETase mutants without GPU recomputation. The comparison uses a supervised ML proxy for ESM — see Section 2 for details.\n",
    "- Conservation produces far fewer unique scores (many tied predictions) — Section 3 analyzes the NDCG implications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "UG8WU5iT_pXd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UG8WU5iT_pXd",
    "outputId": "f81649ab-82e9-4787-8d0e-db37146384fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'pet-challenge-2025'...\n",
      "remote: Enumerating objects: 349, done.\u001b[K\n",
      "remote: Counting objects: 100% (349/349), done.\u001b[K\n",
      "remote: Compressing objects: 100% (263/263), done.\u001b[K\n",
      "remote: Total 349 (delta 176), reused 257 (delta 85), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (349/349), 9.77 MiB | 9.28 MiB/s, done.\n",
      "Resolving deltas: 100% (176/176), done.\n",
      "Project root: /content/pet-challenge-2025\n",
      "Working dir:  /content/pet-challenge-2025\n",
      "  OK: data/petase_challenge_data/pet-2025-wildtype-cds.csv (302 KB)\n",
      "  OK: data/petase_challenge_data/predictive-pet-zero-shot-test-2025.csv (1274 KB)\n",
      "  OK: data/mutations_dataset.csv (6 KB)\n",
      "  OK: data/features_matrix.csv (19 KB)\n",
      "  OK: scripts/esm2_zero_shot_scoring.py (17 KB)\n",
      "  OK: scripts/esmc_scoring.py (14 KB)\n",
      "  OK: scripts/compute_cds_features.py (11 KB)\n",
      "  OK: scripts/generate_submission.py (9 KB)\n",
      "  OK: scripts/generate_submission_v2.py (33 KB)\n",
      "  OK: scripts/validate_scores.py (13 KB)\n",
      "\n",
      "All files present!\n",
      "pKa config: USE_PKA=True, STRICT_PKA=True\n"
     ]
    }
   ],
   "source": [
    "# Set project root - handles Colab's /content/ path automatically\n",
    "# If running from within the cloned repo:\n",
    "if os.path.exists('data/petase_challenge_data'):\n",
    "    PROJECT_ROOT = os.getcwd()\n",
    "elif os.path.exists('pet-challenge-2025/data/petase_challenge_data'):\n",
    "    PROJECT_ROOT = os.path.join(os.getcwd(), 'pet-challenge-2025')\n",
    "    os.chdir(PROJECT_ROOT)\n",
    "elif os.path.exists('/content/pet-challenge-2025/data/petase_challenge_data'):\n",
    "    # Google Colab default clone location\n",
    "    PROJECT_ROOT = '/content/pet-challenge-2025'\n",
    "    os.chdir(PROJECT_ROOT)\n",
    "else:\n",
    "    # Clone the repo\n",
    "    !git clone https://github.com/fulopjoz/pet-challenge-2025.git\n",
    "    # Pin to specific commit for reproducibility:\n",
    "    # !git checkout <COMMIT_HASH>  # fill in after final commit\n",
    "    PROJECT_ROOT = os.path.join(os.getcwd(), 'pet-challenge-2025')\n",
    "    os.chdir(PROJECT_ROOT)\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Working dir:  {os.getcwd()}\")\n",
    "\n",
    "# Verify ALL required files exist\n",
    "required_files = [\n",
    "    'data/petase_challenge_data/pet-2025-wildtype-cds.csv',\n",
    "    'data/petase_challenge_data/predictive-pet-zero-shot-test-2025.csv',\n",
    "    'data/mutations_dataset.csv',\n",
    "    'data/features_matrix.csv',\n",
    "    'scripts/esm2_zero_shot_scoring.py',\n",
    "    'scripts/esmc_scoring.py',\n",
    "    'scripts/compute_cds_features.py',\n",
    "    'scripts/generate_submission.py',\n",
    "    'scripts/generate_submission_v2.py',\n",
    "    'scripts/validate_scores.py',\n",
    "]\n",
    "all_ok = True\n",
    "for f in required_files:\n",
    "    path = os.path.join(PROJECT_ROOT, f)\n",
    "    if os.path.exists(path):\n",
    "        size_kb = os.path.getsize(path) / 1024\n",
    "        print(f\"  OK: {f} ({size_kb:.0f} KB)\")\n",
    "    else:\n",
    "        print(f\"  MISSING: {f}\")\n",
    "        all_ok = False\n",
    "\n",
    "if all_ok:\n",
    "    print(\"\\nAll files present!\")\n",
    "else:\n",
    "    print(\"\\nSome files missing - check your clone or upload\")\n",
    "\n",
    "# Make results directory\n",
    "os.makedirs(os.path.join(PROJECT_ROOT, 'results'), exist_ok=True)\n",
    "\n",
    "# pKa usage controls for submission generation section\n",
    "USE_PKA = True\n",
    "STRICT_PKA = True\n",
    "print(f\"pKa config: USE_PKA={USE_PKA}, STRICT_PKA={STRICT_PKA}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41cd0756",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41cd0756",
    "outputId": "f6f0ad16-76ff-4073-a39a-07033ffbca0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approach Comparison Notebook — PET Challenge 2025\n",
      "Project root: /content/pet-challenge-2025\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "matplotlib.rcParams.update({'font.size': 11, 'figure.dpi': 120})\n",
    "\n",
    "# Paths — detect project root (works in Colab, VS Code, and local)\n",
    "if os.path.exists('data/petase_challenge_data'):\n",
    "    PROJECT_ROOT = os.getcwd()\n",
    "elif os.path.exists('pet-challenge-2025/data/petase_challenge_data'):\n",
    "    PROJECT_ROOT = os.path.join(os.getcwd(), 'pet-challenge-2025')\n",
    "    os.chdir(PROJECT_ROOT)\n",
    "elif os.path.exists('/content/pet-challenge-2025/data/petase_challenge_data'):\n",
    "    PROJECT_ROOT = '/content/pet-challenge-2025'\n",
    "    os.chdir(PROJECT_ROOT)\n",
    "else:\n",
    "    raise FileNotFoundError(\n",
    "        'Cannot find data/petase_challenge_data/. '\n",
    "        'Run this notebook from the repo root or clone first.'\n",
    "    )\n",
    "DATA_DIR = os.path.join(PROJECT_ROOT, 'data', 'petase_challenge_data')\n",
    "RESULTS_DIR = os.path.join(PROJECT_ROOT, 'results')\n",
    "\n",
    "CONS_CSV   = os.path.join(RESULTS_DIR, 'submission_conservation.csv')\n",
    "ESM_V4_CSV = os.path.join(RESULTS_DIR, 'submission_zero_shot_v4.csv')\n",
    "ESM_CSV    = os.path.join(RESULTS_DIR, 'submission_zero_shot_v5.csv')\n",
    "WT_CSV     = os.path.join(DATA_DIR, 'pet-2025-wildtype-cds.csv')\n",
    "TEST_CSV   = os.path.join(DATA_DIR, 'predictive-pet-zero-shot-test-2025.csv')\n",
    "FEAT_CSV   = os.path.join(PROJECT_ROOT, 'data', 'features_matrix.csv')\n",
    "MUT_CSV    = os.path.join(PROJECT_ROOT, 'data', 'mutations_dataset.csv')\n",
    "\n",
    "# Target columns (short aliases)\n",
    "TARGETS = {\n",
    "    'act1': 'activity_1 (\\u03bcmol [TPA]/min\\u00b7mg [E])',\n",
    "    'act2': 'activity_2 (\\u03bcmol [TPA]/min\\u00b7mg [E])',\n",
    "    'expr': 'expression (mg/mL)',\n",
    "}\n",
    "TARGET_RANGES = {'act1': (0, 5), 'act2': (0, 5), 'expr': (0, 3)}\n",
    "TARGET_LABELS = {'act1': 'Activity 1 (pH 5.5)', 'act2': 'Activity 2 (pH 9.0)', 'expr': 'Expression'}\n",
    "\n",
    "print(\"Approach Comparison Notebook \\u2014 PET Challenge 2025\")\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceb8bf13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ceb8bf13",
    "outputId": "b022eea1-e2cf-46d1-c4f3-2ed8638ed701"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conservation submission: FOUND — /content/pet-challenge-2025/results/submission_conservation.csv\n",
      "ESM v4 submission:       FOUND — /content/pet-challenge-2025/results/submission_zero_shot_v4.csv\n",
      "ESM v5 submission:       FOUND — /content/pet-challenge-2025/results/submission_zero_shot_v5.csv\n",
      "\n",
      "Conservation: 4988 sequences, columns: ['sequence', 'activity_1 (μmol [TPA]/min·mg [E])', 'activity_2 (μmol [TPA]/min·mg [E])', 'expression (mg/mL)']\n",
      "ESM v4:       4988 sequences, columns: ['sequence', 'activity_1 (μmol [TPA]/min·mg [E])', 'activity_2 (μmol [TPA]/min·mg [E])', 'expression (mg/mL)']\n",
      "ESM v5:       4988 sequences, columns: ['sequence', 'activity_1 (μmol [TPA]/min·mg [E])', 'activity_2 (μmol [TPA]/min·mg [E])', 'expression (mg/mL)']\n",
      "\n",
      "Sequence order: MATCHED across 3 submissions\n",
      "Active submissions: ['Conservation', 'ESM v4', 'ESM v5']\n",
      "\n",
      "WT scaffolds loaded: 313\n",
      "Test set: 314 WT sequences, 4674 mutant sequences\n",
      "WT fraction: 6.3%\n"
     ]
    }
   ],
   "source": [
    "# --- File existence checks ---\n",
    "cons_available = os.path.exists(CONS_CSV)\n",
    "esm_v4_available = os.path.exists(ESM_V4_CSV)\n",
    "esm_v5_available = os.path.exists(ESM_CSV)\n",
    "esm_available = esm_v4_available or esm_v5_available  # backward compat flag\n",
    "\n",
    "print(f\"Conservation submission: {'FOUND' if cons_available else 'MISSING'} \\u2014 {CONS_CSV}\")\n",
    "print(f\"ESM v4 submission:       {'FOUND' if esm_v4_available else 'MISSING'} \\u2014 {ESM_V4_CSV}\")\n",
    "print(f\"ESM v5 submission:       {'FOUND' if esm_v5_available else 'MISSING'} \\u2014 {ESM_CSV}\")\n",
    "\n",
    "if not cons_available:\n",
    "    raise FileNotFoundError(\"Conservation submission is required. Run Conservation_Scoring_Pipeline first.\")\n",
    "\n",
    "# --- Load submissions ---\n",
    "cons = pd.read_csv(CONS_CSV)\n",
    "print(f\"\\nConservation: {len(cons)} sequences, columns: {list(cons.columns)}\")\n",
    "\n",
    "submissions = {'Conservation': cons}\n",
    "\n",
    "if esm_v4_available:\n",
    "    esm_v4 = pd.read_csv(ESM_V4_CSV)\n",
    "    print(f\"ESM v4:       {len(esm_v4)} sequences, columns: {list(esm_v4.columns)}\")\n",
    "    assert list(cons['sequence']) == list(esm_v4['sequence']), \\\n",
    "        \"Sequence order mismatch between Conservation and ESM v4!\"\n",
    "    submissions['ESM v4'] = esm_v4\n",
    "else:\n",
    "    esm_v4 = None\n",
    "\n",
    "if esm_v5_available:\n",
    "    esm_v5 = pd.read_csv(ESM_CSV)\n",
    "    print(f\"ESM v5:       {len(esm_v5)} sequences, columns: {list(esm_v5.columns)}\")\n",
    "    assert list(cons['sequence']) == list(esm_v5['sequence']), \\\n",
    "        \"Sequence order mismatch between Conservation and ESM v5!\"\n",
    "    submissions['ESM v5'] = esm_v5\n",
    "else:\n",
    "    esm_v5 = None\n",
    "\n",
    "# Backward compat: 'esm' points to latest available ESM version\n",
    "esm = esm_v5 if esm_v5_available else esm_v4\n",
    "\n",
    "if esm_available:\n",
    "    print(f\"\\nSequence order: MATCHED across {len(submissions)} submissions\")\n",
    "else:\n",
    "    print(\"\\nNo ESM submissions found \\u2014 comparison cells will show conservation-only analysis.\")\n",
    "    print(\"To enable full comparison, copy submission_zero_shot_v4/v5.csv to results/\")\n",
    "\n",
    "print(f\"Active submissions: {list(submissions.keys())}\")\n",
    "\n",
    "# --- Load WT sequences for WT/mutant classification ---\n",
    "wt_df = pd.read_csv(WT_CSV)\n",
    "wt_set = set(wt_df['Wt AA Sequence'].values)\n",
    "print(f\"\\nWT scaffolds loaded: {len(wt_set)}\")\n",
    "\n",
    "is_wt = cons['sequence'].isin(wt_set).values\n",
    "n_wt = is_wt.sum()\n",
    "n_mut = (~is_wt).sum()\n",
    "print(f\"Test set: {n_wt} WT sequences, {n_mut} mutant sequences\")\n",
    "print(f\"WT fraction: {n_wt/len(cons)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e41283b",
   "metadata": {
    "id": "0e41283b"
   },
   "source": [
    "## 1. Submission-Level Comparison\n",
    "\n",
    "Direct comparison of the two approaches on the 4988 test sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768641bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "id": "768641bf",
    "outputId": "ed47747e-198d-409e-cc98-fb62360c97b4"
   },
   "outputs": [],
   "source": [
    "if not esm_available:\n",
    "    print(\"SKIPPING — No ESM submissions available.\")\n",
    "else:\n",
    "    esm_subs = {k: v for k, v in submissions.items() if k != 'Conservation'}\n",
    "    n_esm = len(esm_subs)\n",
    "    fig, axes = plt.subplots(n_esm, 3, figsize=(16, max(9, 5 * n_esm)), squeeze=False)\n",
    "\n",
    "    for row_idx, (esm_name, esm_df) in enumerate(esm_subs.items()):\n",
    "        for col_idx, (key, col) in enumerate(TARGETS.items()):\n",
    "            ax = axes[row_idx, col_idx]\n",
    "            c_scores = cons[col].values\n",
    "            e_scores = esm_df[col].values\n",
    "\n",
    "            ax.scatter(c_scores[~is_wt], e_scores[~is_wt], s=6, alpha=0.15, c='coral', label='Mutant')\n",
    "            ax.scatter(c_scores[is_wt], e_scores[is_wt], s=12, alpha=0.4, c='steelblue', label='WT')\n",
    "\n",
    "            lo, hi = TARGET_RANGES[key]\n",
    "            ax.plot([lo, hi], [lo, hi], 'k--', alpha=0.3, lw=1)\n",
    "\n",
    "            rho, p_rho = stats.spearmanr(c_scores, e_scores)\n",
    "            tau, p_tau = stats.kendalltau(c_scores, e_scores)\n",
    "            ax.set_title(f\"{TARGET_LABELS[key]}\\nSpearman $\\\\rho$={rho:.3f}, Kendall $\\\\tau$={tau:.3f}\", fontsize=11)\n",
    "            ax.set_xlabel('Conservation score')\n",
    "            ax.set_ylabel(f'{esm_name} score')\n",
    "            ax.legend(fontsize=8, loc='lower right')\n",
    "\n",
    "    plt.suptitle('ESM vs Conservation — Per-Target Score Comparison', fontsize=13, fontweight='bold')\n",
    "    plt.tight_layout(h_pad=3)\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, 'comparison_scatter.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"Saved: results/comparison_scatter.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd26df3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "id": "dfd26df3",
    "outputId": "86254ded-0e22-4884-ceb4-203615f680be"
   },
   "outputs": [],
   "source": [
    "if not esm_available:\n",
    "    print(\"SKIPPING — No ESM submissions available.\")\n",
    "else:\n",
    "    esm_subs = {k: v for k, v in submissions.items() if k != 'Conservation'}\n",
    "    K_values = [20, 50, 100, 200, 500]\n",
    "    n_esm = len(esm_subs)\n",
    "    fig, axes = plt.subplots(n_esm, 3, figsize=(16, max(9, 5 * n_esm)), squeeze=False)\n",
    "\n",
    "    for row_idx, (esm_name, esm_df) in enumerate(esm_subs.items()):\n",
    "        for col_idx, (key, col) in enumerate(TARGETS.items()):\n",
    "            ax = axes[row_idx, col_idx]\n",
    "            c_ranks = stats.rankdata(-cons[col].values)\n",
    "            e_ranks = stats.rankdata(-esm_df[col].values)\n",
    "\n",
    "            shared_counts = []\n",
    "            jaccard_vals = []\n",
    "            for K in K_values:\n",
    "                c_topk = set(np.where(c_ranks <= K)[0])\n",
    "                e_topk = set(np.where(e_ranks <= K)[0])\n",
    "                overlap = len(c_topk & e_topk)\n",
    "                jaccard = overlap / len(c_topk | e_topk) if len(c_topk | e_topk) > 0 else 0\n",
    "                shared_counts.append(overlap)\n",
    "                jaccard_vals.append(jaccard)\n",
    "\n",
    "            x = np.arange(len(K_values))\n",
    "            width = 0.35\n",
    "            ax.bar(x - width/2, shared_counts, width, color='steelblue', edgecolor='white', label='Shared')\n",
    "            ax.bar(x + width/2, [K - s for K, s in zip(K_values, shared_counts)], width,\n",
    "                   color='coral', edgecolor='white', label='Unique (each)')\n",
    "\n",
    "            for i, (j, k) in enumerate(zip(jaccard_vals, K_values)):\n",
    "                ax.text(i, k * 0.95, f'J={j:.2f}', ha='center', va='top', fontsize=8, fontweight='bold')\n",
    "\n",
    "            ax.set_xticks(x)\n",
    "            ax.set_xticklabels([f'Top {K}' for K in K_values], fontsize=9)\n",
    "            ax.set_ylabel('Number of sequences')\n",
    "            ax.set_title(f'{esm_name}: {TARGET_LABELS[key]}', fontsize=11)\n",
    "            ax.legend(fontsize=8, loc='upper left')\n",
    "\n",
    "    plt.suptitle('Top-K Overlap Between Approaches', fontsize=13, fontweight='bold')\n",
    "    plt.tight_layout(h_pad=3)\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, 'comparison_topk_overlap.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"Saved: results/comparison_topk_overlap.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "jryw9awfiz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jryw9awfiz",
    "outputId": "9de817e2-c656-4f69-866a-d320690a4605"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping test sequences to parent WT scaffolds...\n",
      "\n",
      "Top 3 scaffolds by mutant count: ['...PGPSTGLFAPVSASMNTCPF', '...FLCPLMDNTGIRSYQSTCPL', '...FIDPGPRTGITTGVSDYRLG']\n",
      "  Mutant counts: [1558 1558 1558]\n",
      "\n",
      "======================================================================\n",
      "Scaffold 1 (1558 mutants)\n",
      "======================================================================\n",
      "\n",
      "  Activity 1 (pH 5.5) — Top-10 rank disagreements (of 1558):\n",
      "   seq_idx  cons_rank ESM v5_rank  |diff|  cons_score ESM v5_score\n",
      "  -----------------------------------------------------------------\n",
      "       232       1308        218    1090      0.7259      3.5161\n",
      "      1090        419       1501    1081      3.4946      0.1093\n",
      "      1094        218       1280    1062      4.1097      0.5574\n",
      "      1302       1424        388    1036      0.4051      2.9396\n",
      "      1096        419       1444    1024      3.4946      0.2025\n",
      "      1387       1301        286    1015      0.7409      3.2745\n",
      "       345        548       1509     960      2.9522      0.0983\n",
      "      1078        491       1439     947      3.1477      0.2095\n",
      "      1310       1531        584     947      0.0536      2.3722\n",
      "       346        548       1475     926      2.9522      0.1434\n",
      "\n",
      "  Activity 2 (pH 9.0) — Top-10 rank disagreements (of 1558):\n",
      "   seq_idx  cons_rank ESM v5_rank  |diff|  cons_score ESM v5_score\n",
      "  -----------------------------------------------------------------\n",
      "      1090         91       1341    1249      4.7659      0.4662\n",
      "      1096         91       1230    1138      4.7659      0.7449\n",
      "      1078        171       1292    1120      4.1754      0.5915\n",
      "       232       1290        230    1060      0.7630      3.6475\n",
      "      1094        204       1258    1054      4.0846      0.6788\n",
      "      1084        171       1186    1014      4.1754      0.8713\n",
      "      1302       1412        436     976      0.4311      3.0138\n",
      "      1387       1284        325     959      0.7770      3.3587\n",
      "      1351        600       1533     933      2.8404      0.0592\n",
      "      1339        401       1330     929      3.5623      0.4963\n",
      "\n",
      "  Expression — Top-10 rank disagreements (of 1558):\n",
      "   seq_idx  cons_rank ESM v5_rank  |diff|  cons_score ESM v5_score\n",
      "  -----------------------------------------------------------------\n",
      "      1090        228       1479    1250      2.4661      0.2436\n",
      "      1096        228       1431    1202      2.4661      0.3453\n",
      "      1302       1447        304    1143      0.1913      2.2547\n",
      "      1094        228       1345    1116      2.4661      0.5185\n",
      "      1310       1447        334    1113      0.1913      2.2077\n",
      "       232       1247        161    1086      0.5053      2.5230\n",
      "      1387       1241        214    1027      0.5228      2.4297\n",
      "       456        228       1235    1006      2.4661      0.7044\n",
      "      1078        395       1389     993      2.1340      0.4361\n",
      "       752       1340        352     988      0.2999      2.1741\n",
      "\n",
      "======================================================================\n",
      "Scaffold 2 (1558 mutants)\n",
      "======================================================================\n",
      "\n",
      "  Activity 1 (pH 5.5) — Top-10 rank disagreements (of 1558):\n",
      "   seq_idx  cons_rank ESM v5_rank  |diff|  cons_score ESM v5_score\n",
      "  -----------------------------------------------------------------\n",
      "      2690       1497        338    1159      0.1629      4.1749\n",
      "      1756       1306        171    1135      0.7259      4.5067\n",
      "      2294        303       1415    1111      3.7322      1.0056\n",
      "      1890        226       1307    1080      3.9367      1.4067\n",
      "      1819        307       1375    1067      3.7182      1.1670\n",
      "      1790       1317        256    1061      0.6763      4.3323\n",
      "      2110       1259        234    1025      0.9590      4.3714\n",
      "      2123         71       1085    1014      4.7183      2.1305\n",
      "      1929       1277        277    1000      0.8733      4.2881\n",
      "      2290         90       1089     999      4.6476      2.1245\n",
      "\n",
      "  Activity 2 (pH 9.0) — Top-10 rank disagreements (of 1558):\n",
      "   seq_idx  cons_rank ESM v5_rank  |diff|  cons_score ESM v5_score\n",
      "  -----------------------------------------------------------------\n",
      "      1756       1286        177    1109      0.7630      4.4576\n",
      "      1817         94       1201    1106      4.6536      1.5931\n",
      "      1890        235       1325    1089      3.9197      1.2422\n",
      "      2294        266       1353    1086      3.8656      1.0999\n",
      "      2302        102       1183    1080      4.6356      1.6383\n",
      "      2129         72       1142    1069      4.7007      1.7616\n",
      "      2296        102       1171    1068      4.6356      1.6734\n",
      "      2515         72       1138    1065      4.7007      1.7726\n",
      "      1819        311       1368    1056      3.7111      1.0567\n",
      "      1790       1299        270    1029      0.7043      4.2250\n",
      "\n",
      "  Expression — Top-10 rank disagreements (of 1558):\n",
      "   seq_idx  cons_rank ESM v5_rank  |diff|  cons_score ESM v5_score\n",
      "  -----------------------------------------------------------------\n",
      "      2515        230       1382    1152      2.3196      0.7995\n",
      "      1756       1265        123    1142      0.5053      2.8322\n",
      "      2294        283       1426    1142      2.2381      0.6822\n",
      "      1817        268       1402    1133      2.2574      0.7423\n",
      "      2129        230       1362    1132      2.3196      0.8344\n",
      "      1890        211       1329    1117      2.3341      0.9066\n",
      "      2302        283       1384    1100      2.2381      0.7911\n",
      "      1790       1289        195    1094      0.4412      2.7618\n",
      "      2690       1229        147    1082      0.5459      2.8117\n",
      "      2296        283       1365    1081      2.2381      0.8290\n",
      "\n",
      "======================================================================\n",
      "Scaffold 3 (1558 mutants)\n",
      "======================================================================\n",
      "\n",
      "  Activity 1 (pH 5.5) — Top-10 rank disagreements (of 1558):\n",
      "   seq_idx  cons_rank ESM v5_rank  |diff|  cons_score ESM v5_score\n",
      "  -----------------------------------------------------------------\n",
      "      3362        113       1280    1167      4.6701      0.8502\n",
      "      3333       1337        273    1064      0.7259      4.1097\n",
      "      3479       1144        122    1022      1.2673      4.5358\n",
      "      3368        444       1439     995      3.2825      0.4311\n",
      "      4378       1516        534     982      0.1629      3.3307\n",
      "      4439        399       1350     950      3.4294      0.6567\n",
      "      3629       1249        305     944      0.9590      4.0225\n",
      "      3363        113       1055     942      4.6701      1.5621\n",
      "      3374        444       1377     933      3.2825      0.5986\n",
      "      3372        286       1205     918      3.8485      1.0608\n",
      "\n",
      "  Activity 2 (pH 9.0) — Top-10 rank disagreements (of 1558):\n",
      "   seq_idx  cons_rank ESM v5_rank  |diff|  cons_score ESM v5_score\n",
      "  -----------------------------------------------------------------\n",
      "      3368        129       1184    1054      4.6737      1.1139\n",
      "      3333       1338        292    1046      0.7630      4.1207\n",
      "      3362        421       1444    1023      3.3016      0.3469\n",
      "      3479       1158        140    1018      1.2934      4.5589\n",
      "      4439        106       1109    1002      4.7378      1.3525\n",
      "      3374        129       1094     964      4.6737      1.3986\n",
      "      3629       1263        316     947      0.9399      4.0465\n",
      "      3447       1348        415     933      0.7354      3.7317\n",
      "      3176       1156        261     895      1.3049      4.2109\n",
      "      3589        586       1478     891      2.8349      0.2537\n",
      "\n",
      "  Expression — Top-10 rank disagreements (of 1558):\n",
      "   seq_idx  cons_rank ESM v5_rank  |diff|  cons_score ESM v5_score\n",
      "  -----------------------------------------------------------------\n",
      "      3333       1323        206    1117      0.5053      2.1476\n",
      "      3362        317       1422    1104      2.2799      0.1173\n",
      "      3368        317       1385    1067      2.2799      0.1492\n",
      "      3479       1135         79    1056      0.7628      2.4923\n",
      "      4439        230       1283    1052      2.4120      0.2533\n",
      "      3335       1402        398    1004      0.3685      1.7127\n",
      "      3374        317       1321    1003      2.2799      0.2130\n",
      "      3629       1226        249     977      0.6410      2.0670\n",
      "      4378       1298        327     971      0.5459      1.8516\n",
      "      3371        317       1269     951      2.2799      0.2695\n",
      "\n",
      "(Rank disagreement = |conservation_rank - ESM v5_rank| within each scaffold)\n"
     ]
    }
   ],
   "source": [
    "if not esm_available:\n",
    "    print(\"SKIPPING \\u2014 No ESM submissions available for rank disagreement analysis.\")\n",
    "else:\n",
    "    # Map each test sequence to its parent WT scaffold\n",
    "    wt_seqs = list(wt_df['Wt AA Sequence'].values)\n",
    "    test_seqs = cons['sequence'].values\n",
    "\n",
    "    def find_parent_wt(seq, wt_list):\n",
    "        \"\"\"Find the WT scaffold with highest similarity to seq.\"\"\"\n",
    "        if seq in wt_set:\n",
    "            return seq  # it IS a WT\n",
    "        best_wt, best_ratio = None, 0\n",
    "        for wt in wt_list:\n",
    "            if len(wt) != len(seq):\n",
    "                continue  # mutations don't change length\n",
    "            mismatches = sum(1 for a, b in zip(seq, wt) if a != b)\n",
    "            ratio = 1 - mismatches / len(seq)\n",
    "            if ratio > best_ratio:\n",
    "                best_ratio = ratio\n",
    "                best_wt = wt\n",
    "        return best_wt\n",
    "\n",
    "    # Build scaffold map\n",
    "    print(\"Mapping test sequences to parent WT scaffolds...\")\n",
    "    parent_wt = []\n",
    "    for seq in test_seqs:\n",
    "        parent_wt.append(find_parent_wt(seq, wt_seqs))\n",
    "\n",
    "    cons_work = cons.copy()\n",
    "    cons_work['parent_wt'] = parent_wt\n",
    "\n",
    "    # Count sequences per scaffold (only scaffolds with mutants)\n",
    "    scaffold_counts = cons_work[~is_wt].groupby('parent_wt').size()\n",
    "    top_scaffolds = scaffold_counts.nlargest(3).index.tolist()\n",
    "    print(f\"\\nTop 3 scaffolds by mutant count: {[f'...{s[-20:]}' for s in top_scaffolds]}\")\n",
    "    print(f\"  Mutant counts: {scaffold_counts.nlargest(3).values}\")\n",
    "\n",
    "    # For each top scaffold, compute within-scaffold rank disagreement\n",
    "    esm_label = 'ESM v5' if esm_v5_available else 'ESM v4'\n",
    "    for scaffold_idx, scaffold_wt in enumerate(top_scaffolds):\n",
    "        mask = (cons_work['parent_wt'] == scaffold_wt) & (~is_wt)\n",
    "        n_muts = mask.sum()\n",
    "        scaffold_short = f\"Scaffold {scaffold_idx + 1} ({n_muts} mutants)\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"{scaffold_short}\")\n",
    "        print(f\"{'='*70}\")\n",
    "\n",
    "        for key, col in TARGETS.items():\n",
    "            c_scores = cons[col].values[mask]\n",
    "            e_scores = esm[col].values[mask]\n",
    "\n",
    "            # Within-scaffold ranks (1 = best)\n",
    "            c_ranks = stats.rankdata(-c_scores)\n",
    "            e_ranks = stats.rankdata(-e_scores)\n",
    "            rank_diff = np.abs(c_ranks - e_ranks)\n",
    "\n",
    "            # Build disagreement table\n",
    "            idx_arr = np.where(mask)[0]\n",
    "            disagree_df = pd.DataFrame({\n",
    "                'seq_idx': idx_arr,\n",
    "                'cons_rank': c_ranks.astype(int),\n",
    "                f'{esm_label}_rank': e_ranks.astype(int),\n",
    "                'rank_diff': rank_diff.astype(int),\n",
    "                'cons_score': c_scores,\n",
    "                f'{esm_label}_score': e_scores,\n",
    "            })\n",
    "            disagree_df = disagree_df.sort_values('rank_diff', ascending=False).head(10)\n",
    "\n",
    "            print(f\"\\n  {TARGET_LABELS[key]} \\u2014 Top-10 rank disagreements (of {n_muts}):\")\n",
    "            print(f\"  {'seq_idx':>8} {'cons_rank':>10} {esm_label+'_rank':>10} {'|diff|':>7} {'cons_score':>11} {esm_label+'_score':>11}\")\n",
    "            print(f\"  {'-'*65}\")\n",
    "            for _, row in disagree_df.iterrows():\n",
    "                print(f\"  {int(row['seq_idx']):>8} {int(row['cons_rank']):>10} \"\n",
    "                      f\"{int(row[f'{esm_label}_rank']):>10} {int(row['rank_diff']):>7} \"\n",
    "                      f\"{row['cons_score']:>11.4f} {row[f'{esm_label}_score']:>11.4f}\")\n",
    "\n",
    "    print(f\"\\n(Rank disagreement = |conservation_rank - {esm_label}_rank| within each scaffold)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284a8410",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "284a8410",
    "outputId": "db17ad6f-41fa-4705-9d63-07473dbfd7ab"
   },
   "outputs": [],
   "source": [
    "def cohens_d(group1, group2):\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    var1, var2 = np.var(group1, ddof=1), np.var(group2, ddof=1)\n",
    "    pooled_std = np.sqrt(((n1 - 1) * var1 + (n2 - 1) * var2) / (n1 + n2 - 2))\n",
    "    return (np.mean(group1) - np.mean(group2)) / pooled_std if pooled_std > 0 else 0\n",
    "\n",
    "def mann_whitney_auc(group1, group2):\n",
    "    u, _ = stats.mannwhitneyu(group1, group2, alternative='greater')\n",
    "    return u / (len(group1) * len(group2))\n",
    "\n",
    "approaches = list(submissions.items())\n",
    "color_cycle = {'Conservation': ('steelblue', 'coral'),\n",
    "               'ESM v4': ('forestgreen', 'darkorange'),\n",
    "               'ESM v5': ('purple', 'gold')}\n",
    "\n",
    "n_rows = len(approaches)\n",
    "fig, axes = plt.subplots(n_rows, 3, figsize=(16, max(10, 5 * n_rows)))\n",
    "if n_rows == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "sep_stats = []\n",
    "\n",
    "for row_idx, (name, df) in enumerate(approaches):\n",
    "    c_wt, c_mut = color_cycle.get(name, ('steelblue', 'coral'))\n",
    "    for col_idx, (key, col) in enumerate(TARGETS.items()):\n",
    "        ax = axes[row_idx, col_idx]\n",
    "        wt_scores = df[col].values[is_wt]\n",
    "        mut_scores = df[col].values[~is_wt]\n",
    "\n",
    "        ax.hist(wt_scores, bins=30, alpha=0.7, color=c_wt, edgecolor='white', label='WT', density=True)\n",
    "        ax.hist(mut_scores, bins=30, alpha=0.5, color=c_mut, edgecolor='white', label='Mutant', density=True)\n",
    "\n",
    "        d = cohens_d(wt_scores, mut_scores)\n",
    "        auc = mann_whitney_auc(wt_scores, mut_scores)\n",
    "        sep_stats.append({'Approach': name, 'Target': TARGET_LABELS[key],\n",
    "                          'Cohen_d': d, 'MW_AUC': auc,\n",
    "                          'WT_mean': np.mean(wt_scores), 'Mut_mean': np.mean(mut_scores)})\n",
    "\n",
    "        ax.set_title(f\"{name} — {TARGET_LABELS[key]}\\nCohen's d={d:.2f}, AUC={auc:.3f}\", fontsize=10)\n",
    "        ax.set_xlabel('Score')\n",
    "        ax.set_ylabel('Density')\n",
    "        ax.legend(fontsize=8)\n",
    "\n",
    "plt.suptitle('WT vs Mutant Score Separation', fontsize=13, fontweight='bold')\n",
    "plt.tight_layout(h_pad=3)\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'comparison_wt_separation.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "sep_df = pd.DataFrame(sep_stats)\n",
    "print(\"\\nWT/Mutant Separation Statistics:\")\n",
    "print(sep_df.to_string(index=False, float_format='%.3f'))\n",
    "print(\"\\nSaved: results/comparison_wt_separation.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "py3uh96rm3d",
   "metadata": {},
   "source": [
    "## 1.5 Score Granularity & NDCG Impact\n",
    "\n",
    "The competition metric is **NDCG** (Normalized Discounted Cumulative Gain), which evaluates ranking quality. When two sequences receive identical predicted scores, their relative order is random — NDCG penalizes this because the evaluator cannot distinguish them.\n",
    "\n",
    "**Key question:** How many unique scores does each approach produce? A method with massive ties will underperform on NDCG even if its broad ranking is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k1w3i1pldmg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Score Granularity & NDCG Tie-Rate Analysis ===\n",
    "from itertools import combinations\n",
    "\n",
    "granularity_rows = []\n",
    "for name, df in submissions.items():\n",
    "    for key, col in TARGETS.items():\n",
    "        scores = df[col].values\n",
    "        n_total = len(scores)\n",
    "        n_unique = len(np.unique(scores))\n",
    "        tie_fraction = 1.0 - (n_unique / n_total)\n",
    "\n",
    "        # Within-scaffold analysis: score variance among mutants of top-3 scaffolds\n",
    "        # (measures whether method can distinguish mutations within same WT)\n",
    "        esm2_scores_path = os.path.join(RESULTS_DIR, 'esm2_scores.csv')\n",
    "        if os.path.exists(esm2_scores_path):\n",
    "            esm2_raw = pd.read_csv(esm2_scores_path)\n",
    "            wt_idx = esm2_raw['wt_idx'].values\n",
    "            # Top-3 scaffolds by mutant count\n",
    "            from collections import Counter\n",
    "            wt_counts = Counter(wt_idx)\n",
    "            top3_wts = [w for w, _ in wt_counts.most_common(3)]\n",
    "            within_stds = []\n",
    "            for wt in top3_wts:\n",
    "                mask = (wt_idx == wt) & (esm2_raw['n_mutations'].values > 0)\n",
    "                if mask.sum() > 1:\n",
    "                    within_stds.append(np.std(scores[mask]))\n",
    "            avg_within_std = np.mean(within_stds) if within_stds else 0.0\n",
    "        else:\n",
    "            avg_within_std = np.nan\n",
    "\n",
    "        granularity_rows.append({\n",
    "            'Approach': name,\n",
    "            'Target': TARGET_LABELS[key],\n",
    "            'Total': n_total,\n",
    "            'Unique Scores': n_unique,\n",
    "            'Tie Fraction': tie_fraction,\n",
    "            'Within-Scaffold Std': avg_within_std,\n",
    "        })\n",
    "\n",
    "gran_df = pd.DataFrame(granularity_rows)\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5.5))\n",
    "\n",
    "# Panel 1: Unique scores bar chart\n",
    "approach_names = list(submissions.keys())\n",
    "x = np.arange(len(TARGETS))\n",
    "width = 0.8 / len(approach_names)\n",
    "colors = {'Conservation': 'steelblue', 'ESM v4': 'forestgreen', 'ESM v5': 'purple'}\n",
    "for i, name in enumerate(approach_names):\n",
    "    vals = gran_df[gran_df['Approach'] == name]['Unique Scores'].values\n",
    "    bars = axes[0].bar(x + i * width - 0.4 + width/2, vals, width,\n",
    "                       color=colors.get(name, 'gray'), label=name, edgecolor='white')\n",
    "    for bar, v in zip(bars, vals):\n",
    "        axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50,\n",
    "                     str(v), ha='center', va='bottom', fontsize=9)\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels([TARGET_LABELS[k] for k in TARGETS], fontsize=10)\n",
    "axes[0].set_ylabel('Unique Scores (of 4988)')\n",
    "axes[0].set_title('Score Granularity\\n(higher = better for NDCG)', fontsize=11)\n",
    "axes[0].legend(fontsize=9)\n",
    "axes[0].set_ylim(0, 5500)\n",
    "\n",
    "# Panel 2: Tie fraction\n",
    "for i, name in enumerate(approach_names):\n",
    "    vals = gran_df[gran_df['Approach'] == name]['Tie Fraction'].values * 100\n",
    "    axes[1].bar(x + i * width - 0.4 + width/2, vals, width,\n",
    "                color=colors.get(name, 'gray'), label=name, edgecolor='white')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels([TARGET_LABELS[k] for k in TARGETS], fontsize=10)\n",
    "axes[1].set_ylabel('Tied Score Fraction (%)')\n",
    "axes[1].set_title('Tie Rate\\n(lower = better for NDCG)', fontsize=11)\n",
    "axes[1].legend(fontsize=9)\n",
    "\n",
    "# Panel 3: Within-scaffold std\n",
    "for i, name in enumerate(approach_names):\n",
    "    vals = gran_df[gran_df['Approach'] == name]['Within-Scaffold Std'].values\n",
    "    axes[2].bar(x + i * width - 0.4 + width/2, vals, width,\n",
    "                color=colors.get(name, 'gray'), label=name, edgecolor='white')\n",
    "axes[2].set_xticks(x)\n",
    "axes[2].set_xticklabels([TARGET_LABELS[k] for k in TARGETS], fontsize=10)\n",
    "axes[2].set_ylabel('Score Std (within top-3 scaffolds)')\n",
    "axes[2].set_title('Within-Scaffold Discrimination\\n(higher = better mutant ranking)', fontsize=11)\n",
    "axes[2].legend(fontsize=9)\n",
    "\n",
    "plt.suptitle('Score Granularity & NDCG Impact', fontsize=13, fontweight='bold')\n",
    "plt.tight_layout(h_pad=2)\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'comparison_granularity.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nScore Granularity Summary:\")\n",
    "print(gran_df.to_string(index=False, float_format='%.4f'))\n",
    "print(\"\\nConservation's ~1700 unique scores (vs ESM's ~4987) mean ~65% of sequence pairs share\")\n",
    "print(\"identical scores. Under NDCG, tied pairs are ranked randomly — significant penalty.\")\n",
    "print(\"Saved: results/comparison_granularity.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63897887",
   "metadata": {
    "id": "63897887"
   },
   "source": [
    "## 2. IsPETase Validation\n",
    "\n",
    "The 10 single-point IsPETase mutants with experimentally measured delta-Tm (Son 2019) provide a small but direct validation set.\n",
    "\n",
    "**Important constraint:** IsPETase is *not* one of the 313 challenge scaffolds, so these mutants are **not** in the 4988 test set. ESM2 zero-shot delta log-likelihood scores cannot be computed for these mutants without GPU recomputation.\n",
    "\n",
    "### Comparison Protocol\n",
    "\n",
    "| Panel | Conservation | ESM |\n",
    "|-------|-------------|-----|\n",
    "| **A: Zero-shot** (10 mutants) | Table S6 conservation score vs delta-Tm | *Not available* — IsPETase not in test set |\n",
    "| **B: Supervised ML proxy** (31 variants, LOOCV) | Ridge on conservation-derived features | Ridge on ESM-derived features |\n",
    "\n",
    "Panel B uses **identical protocol** (LOOCV Ridge regression) on the **same 31 IsPETase variants** from `features_matrix.csv`, making it a fair apples-to-apples comparison. However, it measures *supervised ML* quality, not zero-shot prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60da175e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "60da175e",
    "outputId": "8dc5c5dc-8e61-44de-94cb-e6adaaa923f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single-point IsPETase mutants: 10\n",
      "Variants: ['D186V', 'D186H', 'D186I', 'D186F', 'D186L', 'P181A', 'S121E', 'S121D', 'P181S', 'P181G']\n",
      "\n",
      "--- IsPETase Single-Point Mutant Validation ---\n",
      "Mutation      Pos In S6? Cons Score  delta-Tm\n",
      "--------------------------------------------------\n",
      "D186V         186     No     0.0000      4.65\n",
      "D186H         186     No     0.0000      4.35\n",
      "D186I         186     No     0.0000      3.89\n",
      "D186F         186     No     0.0000      3.09\n",
      "D186L         186     No     0.0000      2.86\n",
      "P181A         181    Yes    -0.7895      0.44\n",
      "S121E         121     No     0.0000     -1.13\n",
      "S121D         121     No     0.0000     -1.46\n",
      "P181S         181    Yes    -0.7895     -2.89\n",
      "P181G         181    Yes    -0.7895     -5.02\n",
      "\n",
      "Spearman rho = 0.646, p = 0.0437\n",
      "(Positive rho means: higher conservation score ~ higher delta-Tm — correct direction)\n"
     ]
    }
   ],
   "source": [
    "# Table S6 from Buchholz et al. (Proteins, 2022)\n",
    "# {ispetase_position: (consensus_aa, conservation_frequency_pct)}\n",
    "TABLE_S6 = {\n",
    "    32: (\"Y\", 74), 34: (\"R\", 84), 35: (\"G\", 91), 36: (\"P\", 92),\n",
    "    38: (\"P\", 95), 39: (\"T\", 87), 42: (\"S\", 73), 45: (\"A\", 87),\n",
    "    48: (\"G\", 97), 49: (\"P\", 71), 57: (\"V\", 91), 62: (\"G\", 93),\n",
    "    63: (\"F\", 93), 64: (\"G\", 83), 65: (\"G\", 86), 66: (\"G\", 93),\n",
    "    67: (\"T\", 76), 68: (\"I\", 79), 69: (\"Y\", 84), 70: (\"Y\", 91),\n",
    "    71: (\"P\", 98), 72: (\"T\", 85), 74: (\"T\", 81), 76: (\"G\", 90),\n",
    "    77: (\"T\", 84), 78: (\"F\", 74), 79: (\"G\", 90), 80: (\"A\", 77),\n",
    "    85: (\"P\", 99), 86: (\"G\", 100), 88: (\"T\", 76), 92: (\"S\", 70),\n",
    "    96: (\"W\", 93), 98: (\"G\", 89), 99: (\"P\", 82), 100: (\"R\", 81),\n",
    "    101: (\"L\", 81), 102: (\"A\", 97), 103: (\"S\", 96), 105: (\"G\", 99),\n",
    "    106: (\"F\", 97), 107: (\"V\", 96), 108: (\"V\", 94), 111: (\"I\", 84),\n",
    "    113: (\"T\", 96), 118: (\"D\", 98), 120: (\"P\", 87), 122: (\"S\", 71),\n",
    "    123: (\"R\", 99), 124: (\"G\", 73), 126: (\"Q\", 92), 127: (\"L\", 83),\n",
    "    128: (\"L\", 78), 129: (\"A\", 88), 130: (\"A\", 96), 131: (\"L\", 88),\n",
    "    132: (\"D\", 82), 133: (\"Y\", 77), 134: (\"L\", 85), 138: (\"S\", 83),\n",
    "    145: (\"V\", 82), 146: (\"R\", 71), 148: (\"R\", 81), 150: (\"D\", 94),\n",
    "    153: (\"R\", 94), 154: (\"L\", 85), 156: (\"V\", 89), 158: (\"G\", 100),\n",
    "    159: (\"H\", 87), 160: (\"S\", 100), 161: (\"M\", 94), 162: (\"G\", 100),\n",
    "    163: (\"G\", 99), 164: (\"G\", 96), 165: (\"G\", 97), 167: (\"L\", 88),\n",
    "    169: (\"A\", 89), 170: (\"A\", 82), 173: (\"R\", 76), 174: (\"P\", 76),\n",
    "    176: (\"L\", 84), 178: (\"A\", 95), 179: (\"A\", 78), 181: (\"P\", 80),\n",
    "    182: (\"L\", 79), 184: (\"P\", 76), 185: (\"W\", 77), 197: (\"P\", 97),\n",
    "    198: (\"T\", 93), 202: (\"G\", 75), 206: (\"D\", 100), 209: (\"A\", 87),\n",
    "    211: (\"V\", 70), 214: (\"H\", 77), 217: (\"P\", 79), 218: (\"F\", 74),\n",
    "    219: (\"Y\", 96), 221: (\"S\", 70), 228: (\"A\", 77), 229: (\"Y\", 83),\n",
    "    231: (\"E\", 91), 232: (\"L\", 76), 235: (\"A\", 76), 237: (\"H\", 100),\n",
    "    240: (\"P\", 74), 244: (\"N\", 74), 257: (\"W\", 90), 258: (\"L\", 80),\n",
    "    259: (\"K\", 94), 260: (\"R\", 78), 261: (\"F\", 79), 263: (\"D\", 94),\n",
    "    265: (\"D\", 97), 266: (\"T\", 76), 267: (\"R\", 96), 268: (\"Y\", 92),\n",
    "    270: (\"Q\", 77), 271: (\"F\", 96), 272: (\"L\", 86), 273: (\"C\", 95),\n",
    "    274: (\"P\", 82),\n",
    "}\n",
    "\n",
    "# Load mutations dataset — filter single-point IsPETase mutants\n",
    "mut_df = pd.read_csv(MUT_CSV)\n",
    "features_df = pd.read_csv(FEAT_CSV)\n",
    "\n",
    "# Single-point mutants: N_mutations == 1 in features_matrix\n",
    "single_mask = features_df['N_mutations'] == 1\n",
    "single_variants = features_df.loc[single_mask, 'variant_name'].values\n",
    "single_df = mut_df[mut_df['variant_name'].isin(single_variants)].copy()\n",
    "print(f\"Single-point IsPETase mutants: {len(single_df)}\")\n",
    "print(f\"Variants: {list(single_df['variant_name'].values)}\")\n",
    "\n",
    "# Parse mutation: e.g. \"D186H\" -> (pos=186, wt_aa='D', mut_aa='H')\n",
    "def parse_single_mutation(mut_str):\n",
    "    wt_aa = mut_str[0]\n",
    "    mut_aa = mut_str[-1]\n",
    "    pos = int(mut_str[1:-1])\n",
    "    return pos, wt_aa, mut_aa\n",
    "\n",
    "# Conservation score for each mutant\n",
    "cons_scores = []\n",
    "for _, row in single_df.iterrows():\n",
    "    pos, wt_aa, mut_aa = parse_single_mutation(row['mutation'])\n",
    "    if pos in TABLE_S6:\n",
    "        consensus_aa, freq_pct = TABLE_S6[pos]\n",
    "        # Penalty: frequency of consensus (WT) minus estimated frequency of mutant\n",
    "        # If WT matches consensus, use table freq; otherwise estimate lower\n",
    "        wt_freq = freq_pct / 100.0 if wt_aa == consensus_aa else (100 - freq_pct) / (19 * 100.0)\n",
    "        mut_freq = freq_pct / 100.0 if mut_aa == consensus_aa else (100 - freq_pct) / (19 * 100.0)\n",
    "        score = -(wt_freq - mut_freq)  # negative penalty = less damage to function\n",
    "    else:\n",
    "        # Position not conserved (< 70%) — mutation has minimal predicted impact\n",
    "        score = 0.0\n",
    "    cons_scores.append(score)\n",
    "\n",
    "single_df = single_df.copy()\n",
    "single_df['cons_score'] = cons_scores\n",
    "single_df['delta_tm'] = single_df['delta_tm'].astype(float)\n",
    "\n",
    "# Print table\n",
    "print(\"\\n--- IsPETase Single-Point Mutant Validation ---\")\n",
    "print(f\"{'Mutation':<12} {'Pos':>4} {'In S6?':>6} {'Cons Score':>10} {'delta-Tm':>9}\")\n",
    "print(\"-\" * 50)\n",
    "for _, row in single_df.iterrows():\n",
    "    pos, wt_aa, mut_aa = parse_single_mutation(row['mutation'])\n",
    "    in_s6 = 'Yes' if pos in TABLE_S6 else 'No'\n",
    "    print(f\"{row['mutation']:<12} {pos:>4} {in_s6:>6} {row['cons_score']:>10.4f} {row['delta_tm']:>9.2f}\")\n",
    "\n",
    "# Spearman correlation\n",
    "rho, pval = stats.spearmanr(single_df['cons_score'], single_df['delta_tm'])\n",
    "print(f\"\\nSpearman rho = {rho:.3f}, p = {pval:.4f}\")\n",
    "print(f\"(Positive rho means: higher conservation score ~ higher delta-Tm — correct direction)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64141ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "f64141ee",
    "outputId": "42838456-7e1f-4859-8474-184d0f7adf78"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "# --- Load features matrix (31 IsPETase variants with Tm) ---\n",
    "feat_df = pd.read_csv(FEAT_CSV)\n",
    "all_feature_cols = [c for c in feat_df.columns if c not in ('variant_name', 'Tm')]\n",
    "X_all = feat_df[all_feature_cols].values\n",
    "y = feat_df['Tm'].values\n",
    "names = feat_df['variant_name'].values\n",
    "\n",
    "# --- Build conservation-derived feature set ---\n",
    "# For each of the 31 variants, compute conservation features from Table S6\n",
    "cons_features = []\n",
    "for _, row in feat_df.iterrows():\n",
    "    # Look up mutation info from mutations_dataset\n",
    "    mut_row = mut_df[mut_df['variant_name'] == row['variant_name']]\n",
    "    if len(mut_row) == 0:\n",
    "        cons_features.append([0, 0, 0, 0])\n",
    "        continue\n",
    "    mut_str = mut_row.iloc[0]['mutation']\n",
    "    mutations = mut_str.split('/')\n",
    "    n_at_conserved = 0\n",
    "    total_penalty = 0.0\n",
    "    max_penalty = 0.0\n",
    "    n_muts = len(mutations)\n",
    "    for m in mutations:\n",
    "        if len(m) < 3:\n",
    "            continue\n",
    "        try:\n",
    "            pos = int(m[1:-1])\n",
    "            wt_aa, mut_aa = m[0], m[-1]\n",
    "        except ValueError:\n",
    "            continue\n",
    "        if pos in TABLE_S6:\n",
    "            consensus_aa, freq_pct = TABLE_S6[pos]\n",
    "            wt_freq = freq_pct / 100.0 if wt_aa == consensus_aa else (100 - freq_pct) / (19 * 100.0)\n",
    "            mut_freq = freq_pct / 100.0 if mut_aa == consensus_aa else (100 - freq_pct) / (19 * 100.0)\n",
    "            penalty = wt_freq - mut_freq\n",
    "            total_penalty += penalty\n",
    "            max_penalty = max(max_penalty, abs(penalty))\n",
    "            n_at_conserved += 1\n",
    "    cons_features.append([n_muts, n_at_conserved, total_penalty, max_penalty])\n",
    "\n",
    "X_cons = np.array(cons_features)\n",
    "cons_feat_names = ['N_mutations', 'N_conserved_positions', 'Total_conservation_penalty', 'Max_conservation_penalty']\n",
    "\n",
    "# --- LOOCV for BOTH approaches with identical protocol ---\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "def loocv_ridge(X, y, alpha=10.0):\n",
    "    scaler = StandardScaler()\n",
    "    y_pred = np.zeros(len(y))\n",
    "    for train_idx, test_idx in loo.split(X):\n",
    "        X_tr = scaler.fit_transform(X[train_idx])\n",
    "        X_te = scaler.transform(X[test_idx])\n",
    "        model = Ridge(alpha=alpha)\n",
    "        model.fit(X_tr, y[train_idx])\n",
    "        y_pred[test_idx] = model.predict(X_te)\n",
    "    return y_pred\n",
    "\n",
    "# ESM features (all 39 columns from features_matrix)\n",
    "y_pred_esm = loocv_ridge(X_all, y)\n",
    "esm_rho, esm_pval = stats.spearmanr(y, y_pred_esm)\n",
    "esm_rmse = np.sqrt(np.mean((y - y_pred_esm) ** 2))\n",
    "\n",
    "# Conservation features (4 columns)\n",
    "y_pred_cons_ml = loocv_ridge(X_cons, y)\n",
    "cons_ml_rho, cons_ml_pval = stats.spearmanr(y, y_pred_cons_ml)\n",
    "cons_ml_rmse = np.sqrt(np.mean((y - y_pred_cons_ml) ** 2))\n",
    "\n",
    "print(\"=== Fair ML Proxy Comparison (LOOCV Ridge, same 31 variants) ===\")\n",
    "print(f\"  Conservation features ({X_cons.shape[1]} cols): rho={cons_ml_rho:.3f}, RMSE={cons_ml_rmse:.1f}C\")\n",
    "print(f\"  ESM features ({X_all.shape[1]} cols):           rho={esm_rho:.3f}, RMSE={esm_rmse:.1f}C\")\n",
    "\n",
    "# --- Visualization: 3 panels ---\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5.5))\n",
    "\n",
    "# Panel A: Conservation zero-shot (10 single-point mutants)\n",
    "ax1.scatter(single_df['cons_score'], single_df['delta_tm'],\n",
    "            s=80, c='steelblue', edgecolors='white', zorder=5, linewidths=0.5)\n",
    "for _, row in single_df.iterrows():\n",
    "    ax1.annotate(row['mutation'], (row['cons_score'], row['delta_tm']),\n",
    "                 fontsize=8, xytext=(6, 4), textcoords='offset points')\n",
    "ax1.axhline(0, ls='--', color='gray', alpha=0.4)\n",
    "ax1.axvline(0, ls='--', color='gray', alpha=0.4)\n",
    "ax1.set_xlabel('Conservation Score')\n",
    "ax1.set_ylabel('$\\\\Delta T_m$ ($\\\\degree$C)')\n",
    "ax1.set_title(f'A: Conservation Zero-Shot\\n$\\\\rho$ = {rho:.3f} (p = {pval:.3f}, n = {len(single_df)})',\n",
    "              fontsize=11)\n",
    "legend1 = [Line2D([0], [0], marker='o', color='w', markerfacecolor='steelblue',\n",
    "                  markersize=8, label=f'n = {len(single_df)} single mutants')]\n",
    "ax1.legend(handles=legend1, fontsize=8, loc='lower right')\n",
    "\n",
    "# Panel B: Conservation ML proxy (31 variants, LOOCV)\n",
    "ax2.scatter(y, y_pred_cons_ml, s=60, c='steelblue', edgecolors='white', zorder=5, linewidths=0.5)\n",
    "lims = [min(y.min(), y_pred_cons_ml.min()) - 2, max(y.max(), y_pred_cons_ml.max()) + 2]\n",
    "ax2.plot(lims, lims, 'r--', alpha=0.5, lw=1.5)\n",
    "ax2.set_xlim(lims)\n",
    "ax2.set_ylim(lims)\n",
    "ax2.set_xlabel('Actual $T_m$ ($\\\\degree$C)')\n",
    "ax2.set_ylabel('Predicted $T_m$ ($\\\\degree$C, LOOCV)')\n",
    "ax2.set_title(f'B: Conservation ML Proxy\\n$\\\\rho$ = {cons_ml_rho:.3f}, RMSE = {cons_ml_rmse:.1f}$\\\\degree$C (n = {len(y)})',\n",
    "              fontsize=11)\n",
    "legend2 = [Line2D([0], [0], marker='o', color='w', markerfacecolor='steelblue', markersize=8, label='Conservation features'),\n",
    "           Line2D([0], [0], ls='--', color='r', alpha=0.5, label='y = x')]\n",
    "ax2.legend(handles=legend2, fontsize=8, loc='lower right')\n",
    "\n",
    "# Panel C: ESM ML proxy (31 variants, LOOCV) — same protocol as Panel B\n",
    "ax3.scatter(y, y_pred_esm, s=60, c='forestgreen', edgecolors='white', zorder=5, linewidths=0.5)\n",
    "lims3 = [min(y.min(), y_pred_esm.min()) - 2, max(y.max(), y_pred_esm.max()) + 2]\n",
    "ax3.plot(lims3, lims3, 'r--', alpha=0.5, lw=1.5)\n",
    "ax3.set_xlim(lims3)\n",
    "ax3.set_ylim(lims3)\n",
    "ax3.set_xlabel('Actual $T_m$ ($\\\\degree$C)')\n",
    "ax3.set_ylabel('Predicted $T_m$ ($\\\\degree$C, LOOCV)')\n",
    "ax3.set_title(f'C: ESM ML Proxy\\n$\\\\rho$ = {esm_rho:.3f}, RMSE = {esm_rmse:.1f}$\\\\degree$C (n = {len(y)})',\n",
    "              fontsize=11)\n",
    "legend3 = [Line2D([0], [0], marker='o', color='w', markerfacecolor='forestgreen', markersize=8, label='ESM features (39 cols)'),\n",
    "           Line2D([0], [0], ls='--', color='r', alpha=0.5, label='y = x')]\n",
    "ax3.legend(handles=legend3, fontsize=8, loc='lower right')\n",
    "\n",
    "plt.suptitle('IsPETase Validation — Zero-Shot vs Fair ML Proxy Comparison', fontsize=13, fontweight='bold')\n",
    "plt.tight_layout(w_pad=2)\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'comparison_ispetase_validation.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: results/comparison_ispetase_validation.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c045f93b",
   "metadata": {
    "id": "c045f93b"
   },
   "source": [
    "## 3. Score Distribution Analysis\n",
    "\n",
    "Compare how each approach distributes scores across the 4988 test sequences.\n",
    "Good ranking requires spread (not all scores clustered together) and discrimination\n",
    "(different sequences get distinguishably different scores).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78a8dd3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "e78a8dd3",
    "outputId": "1ed50086-8000-4bd8-c3a6-e8fd31e8e659"
   },
   "outputs": [],
   "source": [
    "color_map = {'Conservation': 'steelblue', 'ESM v4': 'forestgreen', 'ESM v5': 'purple'}\n",
    "approaches_avail = [(k, v, color_map.get(k, 'gray')) for k, v in submissions.items()]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 12))\n",
    "\n",
    "entropy_stats = []\n",
    "for col_idx, (key, col) in enumerate(TARGETS.items()):\n",
    "    ax_top = axes[0, col_idx]\n",
    "    ax_bot = axes[1, col_idx]\n",
    "\n",
    "    for name, df, color in approaches_avail:\n",
    "        scores = df[col].values\n",
    "\n",
    "        ax_top.hist(scores, bins=50, alpha=0.5, color=color, edgecolor='white',\n",
    "                    density=True, label=name)\n",
    "\n",
    "        ranks = stats.rankdata(scores)\n",
    "        norm_ranks = ranks / len(ranks)\n",
    "        hist_counts, _ = np.histogram(norm_ranks, bins=50, range=(0, 1))\n",
    "        hist_probs = hist_counts / hist_counts.sum()\n",
    "        hist_probs = hist_probs[hist_probs > 0]\n",
    "        rank_entropy = stats.entropy(hist_probs) / np.log(50)\n",
    "        n_unique = len(np.unique(scores))\n",
    "        entropy_stats.append({'Approach': name, 'Target': TARGET_LABELS[key],\n",
    "                              'Rank Entropy': rank_entropy, 'Unique Scores': n_unique,\n",
    "                              'Std': np.std(scores), 'IQR': np.percentile(scores, 75) - np.percentile(scores, 25)})\n",
    "\n",
    "    ax_top.set_title(TARGET_LABELS[key], fontsize=11)\n",
    "    ax_top.set_xlabel('Score')\n",
    "    ax_top.set_ylabel('Density')\n",
    "    ax_top.legend(fontsize=8)\n",
    "\n",
    "    # Bottom row: rank-rank percentile plots (Conservation vs latest ESM)\n",
    "    if esm_available:\n",
    "        c_pctile = stats.rankdata(cons[col].values) / len(cons) * 100\n",
    "        e_pctile = stats.rankdata(esm[col].values) / len(esm) * 100\n",
    "        esm_label = 'ESM v5' if esm_v5_available else 'ESM v4'\n",
    "        ax_bot.scatter(c_pctile, e_pctile, s=3, alpha=0.15, c='gray')\n",
    "        ax_bot.plot([0, 100], [0, 100], 'r--', alpha=0.5, lw=1)\n",
    "        rho_rr, _ = stats.spearmanr(c_pctile, e_pctile)\n",
    "        ax_bot.set_title(f'Rank-Rank ($\\\\rho$ = {rho_rr:.3f})', fontsize=10)\n",
    "        ax_bot.set_xlabel('Conservation percentile')\n",
    "        ax_bot.set_ylabel(f'{esm_label} percentile')\n",
    "        legend_rr = [Line2D([0], [0], ls='--', color='r', alpha=0.5, label='y = x'),\n",
    "                     Line2D([0], [0], marker='o', color='w', markerfacecolor='gray',\n",
    "                            markersize=5, label=f'n = {len(cons)}')]\n",
    "        ax_bot.legend(handles=legend_rr, fontsize=8, loc='lower right')\n",
    "    else:\n",
    "        ax_bot.text(0.5, 0.5, 'ESM not available', ha='center', va='center',\n",
    "                    transform=ax_bot.transAxes, fontsize=12, color='gray')\n",
    "        ax_bot.set_axis_off()\n",
    "\n",
    "plt.suptitle('Score Distributions and Rank Agreement', fontsize=13, fontweight='bold')\n",
    "plt.tight_layout(h_pad=3)\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'comparison_distributions.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "ent_df = pd.DataFrame(entropy_stats)\n",
    "print(\"\\nDistribution Statistics:\")\n",
    "print(ent_df.to_string(index=False, float_format='%.4f'))\n",
    "print(\"\\nRank entropy = 1.0 means perfectly uniform rank distribution (ideal).\")\n",
    "print(\"Saved: results/comparison_distributions.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5931fa8d",
   "metadata": {
    "id": "5931fa8d"
   },
   "source": [
    "## 4. Ensemble Exploration\n",
    "\n",
    "Blend Conservation and ESM scores:\n",
    "**ensemble = alpha * Conservation_rank + (1 - alpha) * ESM_rank**\n",
    "\n",
    "Sweep alpha from 0 (pure ESM) to 1 (pure Conservation) in 51 steps.\n",
    "Evaluate WT/mutant separation (Cohen's d) and ranking entropy at each alpha.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f383b35f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "id": "f383b35f",
    "outputId": "acda8fb3-3152-438a-da6a-49845ce01c07"
   },
   "outputs": [],
   "source": [
    "if not esm_available:\n",
    "    print(\"SKIPPING — ESM submission not available for ensemble exploration.\")\n",
    "else:\n",
    "    alphas = np.linspace(0, 1, 51)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(16, 12))\n",
    "    optimal_alphas = {}\n",
    "\n",
    "    for col_idx, (key, col) in enumerate(TARGETS.items()):\n",
    "        c_ranks = stats.rankdata(cons[col].values)\n",
    "        e_ranks = stats.rankdata(esm[col].values)\n",
    "        c_norm = c_ranks / len(c_ranks)\n",
    "        e_norm = e_ranks / len(e_ranks)\n",
    "\n",
    "        d_vals = []\n",
    "        ent_vals = []\n",
    "        n_unique_vals = []\n",
    "        for alpha in alphas:\n",
    "            blend = alpha * c_norm + (1 - alpha) * e_norm\n",
    "            wt_blend = blend[is_wt]\n",
    "            mut_blend = blend[~is_wt]\n",
    "            d = cohens_d(wt_blend, mut_blend)\n",
    "            d_vals.append(d)\n",
    "\n",
    "            # Rank entropy of blended scores\n",
    "            blend_ranks = stats.rankdata(blend)\n",
    "            norm_br = blend_ranks / len(blend_ranks)\n",
    "            hist_c, _ = np.histogram(norm_br, bins=50, range=(0, 1))\n",
    "            hist_p = hist_c / hist_c.sum()\n",
    "            hist_p = hist_p[hist_p > 0]\n",
    "            ent_vals.append(stats.entropy(hist_p) / np.log(50))\n",
    "            n_unique_vals.append(len(np.unique(blend)))\n",
    "\n",
    "        d_vals = np.array(d_vals)\n",
    "        ent_vals = np.array(ent_vals)\n",
    "        n_unique_vals = np.array(n_unique_vals)\n",
    "\n",
    "        # Optimal alpha: maximize combined score (normalized d * entropy)\n",
    "        # This balances separation strength with ranking granularity\n",
    "        d_norm = d_vals / d_vals.max() if d_vals.max() > 0 else d_vals\n",
    "        combined = d_norm * ent_vals\n",
    "        best_idx = np.argmax(combined)\n",
    "        optimal_alphas[key] = alphas[best_idx]\n",
    "\n",
    "        # Top row: Cohen's d vs alpha (with combined optimum)\n",
    "        ax_d = axes[0, col_idx]\n",
    "        ax_d.plot(alphas, d_vals, 'b-', lw=2, label=\"Cohen's d\")\n",
    "        ax_d.axvline(alphas[best_idx], ls='--', color='red', alpha=0.7,\n",
    "                     label=f'Combined optimum $\\\\alpha$={alphas[best_idx]:.2f}')\n",
    "        ax_d.set_xlabel('$\\\\alpha$ (Conservation weight)')\n",
    "        ax_d.set_ylabel(\"Cohen's d (WT vs Mutant)\")\n",
    "        ax_d.set_title(TARGET_LABELS[key], fontsize=11)\n",
    "        ax_d.legend(fontsize=8)\n",
    "\n",
    "        # Bottom row: Rank entropy + unique scores vs alpha\n",
    "        ax_e = axes[1, col_idx]\n",
    "        ax_e.plot(alphas, ent_vals, 'g-', lw=2, label='Rank entropy')\n",
    "        ax_e2 = ax_e.twinx()\n",
    "        ax_e2.plot(alphas, n_unique_vals, 'orange', lw=1.5, ls='--', label='Unique scores')\n",
    "        ax_e2.set_ylabel('Unique scores', color='orange', fontsize=9)\n",
    "        ax_e2.tick_params(axis='y', labelcolor='orange')\n",
    "        ax_e.axvline(alphas[best_idx], ls='--', color='red', alpha=0.7,\n",
    "                     label=f'Combined optimum $\\\\alpha$={alphas[best_idx]:.2f}')\n",
    "        ax_e.set_xlabel('$\\\\alpha$ (Conservation weight)')\n",
    "        ax_e.set_ylabel('Normalized rank entropy', color='green')\n",
    "        ax_e.tick_params(axis='y', labelcolor='green')\n",
    "        ax_e.set_title(TARGET_LABELS[key], fontsize=11)\n",
    "        lines_e = ax_e.get_lines() + ax_e2.get_lines()\n",
    "        labels_e = [l.get_label() for l in lines_e]\n",
    "        ax_e.legend(lines_e, labels_e, fontsize=7, loc='lower left')\n",
    "\n",
    "    plt.suptitle('Ensemble Alpha Sweep — Separation vs Ranking Quality\\n'\n",
    "                 '(optimum = maximize Cohen\\'s d $\\\\times$ rank entropy)',\n",
    "                 fontsize=13, fontweight='bold')\n",
    "    plt.tight_layout(h_pad=3)\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, 'comparison_ensemble_sweep.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nOptimal alpha per target (maximizes Cohen's d x rank entropy):\")\n",
    "    for key, alpha in optimal_alphas.items():\n",
    "        print(f\"  {TARGET_LABELS[key]}: alpha = {alpha:.2f}\")\n",
    "    print(\"\\nNote: alpha=0 = pure ESM, alpha=1 = pure Conservation\")\n",
    "    print(\"Saved: results/comparison_ensemble_sweep.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6f4257e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e6f4257e",
    "outputId": "a4dbff63-b81c-4e5f-a97a-9717d535fffe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-Approach Spearman Correlation:\n",
      "\n",
      "--- Activity 1 (pH 5.5) ---\n",
      "              Conservation  ESM v4  ESM v5  Ensemble_50\n",
      "Conservation         1.000   0.644   0.636        0.903\n",
      "ESM v4               0.644   1.000   0.997        0.906\n",
      "ESM v5               0.636   0.997   1.000        0.903\n",
      "Ensemble_50          0.903   0.906   0.903        1.000\n",
      "\n",
      "--- Activity 2 (pH 9.0) ---\n",
      "              Conservation  ESM v4  ESM v5  Ensemble_50\n",
      "Conservation         1.000   0.666   0.660        0.910\n",
      "ESM v4               0.666   1.000   0.998        0.912\n",
      "ESM v5               0.660   0.998   1.000        0.910\n",
      "Ensemble_50          0.910   0.912   0.910        1.000\n",
      "\n",
      "--- Expression ---\n",
      "              Conservation  ESM v4  ESM v5  Ensemble_50\n",
      "Conservation         1.000   0.573   0.573        0.886\n",
      "ESM v4               0.573   1.000   1.000        0.886\n",
      "ESM v5               0.573   1.000   1.000        0.886\n",
      "Ensemble_50          0.886   0.886   0.886        1.000\n",
      "\n",
      "Saved: submission_ensemble_50.csv, submission_ensemble_opt.csv\n"
     ]
    }
   ],
   "source": [
    "if not esm_available:\n",
    "    print(\"SKIPPING \\u2014 No ESM submissions available.\")\n",
    "else:\n",
    "    # Generate ensembles (using latest ESM version)\n",
    "    ensemble_50 = cons.copy()\n",
    "    ensemble_opt = cons.copy()\n",
    "\n",
    "    corr_data = {}\n",
    "    for key, col in TARGETS.items():\n",
    "        c_ranks = stats.rankdata(cons[col].values)\n",
    "        e_ranks = stats.rankdata(esm[col].values)\n",
    "        c_norm = c_ranks / len(c_ranks)\n",
    "        e_norm = e_ranks / len(e_ranks)\n",
    "\n",
    "        # alpha = 0.5 ensemble\n",
    "        blend_50 = 0.5 * c_norm + 0.5 * e_norm\n",
    "        lo, hi = TARGET_RANGES[key]\n",
    "        ensemble_50[col] = lo + (stats.rankdata(blend_50) - 1) / (len(blend_50) - 1) * (hi - lo)\n",
    "\n",
    "        # Per-target optimal alpha\n",
    "        alpha_opt = optimal_alphas[key]\n",
    "        blend_opt = alpha_opt * c_norm + (1 - alpha_opt) * e_norm\n",
    "        ensemble_opt[col] = lo + (stats.rankdata(blend_opt) - 1) / (len(blend_opt) - 1) * (hi - lo)\n",
    "\n",
    "        # Spearman between all submissions + ensemble\n",
    "        corr_data[key] = dict(submissions)\n",
    "        corr_data[key] = {k: v[col].values for k, v in submissions.items()}\n",
    "        corr_data[key]['Ensemble_50'] = ensemble_50[col].values\n",
    "\n",
    "    # Print correlation matrix per target\n",
    "    print(\"Inter-Approach Spearman Correlation:\\n\")\n",
    "    for key in TARGETS:\n",
    "        data = corr_data[key]\n",
    "        names_c = list(data.keys())\n",
    "        n = len(names_c)\n",
    "        matrix = np.ones((n, n))\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                rho, _ = stats.spearmanr(data[names_c[i]], data[names_c[j]])\n",
    "                matrix[i, j] = rho\n",
    "                matrix[j, i] = rho\n",
    "        corr_df = pd.DataFrame(matrix, index=names_c, columns=names_c)\n",
    "        print(f\"--- {TARGET_LABELS[key]} ---\")\n",
    "        print(corr_df.to_string(float_format='%.3f'))\n",
    "        print()\n",
    "\n",
    "    # Save ensemble submissions\n",
    "    ensemble_50.to_csv(os.path.join(RESULTS_DIR, 'submission_ensemble_50.csv'), index=False)\n",
    "    ensemble_opt.to_csv(os.path.join(RESULTS_DIR, 'submission_ensemble_opt.csv'), index=False)\n",
    "    print(f\"Saved: submission_ensemble_50.csv, submission_ensemble_opt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead76ac2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "ead76ac2",
    "outputId": "88905b34-02ca-446a-da21-2b32a9951e1f"
   },
   "outputs": [],
   "source": [
    "color_map_ct = {'Conservation': 'steelblue', 'ESM v4': 'forestgreen', 'ESM v5': 'purple'}\n",
    "pairs = [('act1', 'act2'), ('act1', 'expr'), ('act2', 'expr')]\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5.5))\n",
    "\n",
    "for idx, (k1, k2) in enumerate(pairs):\n",
    "    ax = axes[idx]\n",
    "    col1, col2 = TARGETS[k1], TARGETS[k2]\n",
    "\n",
    "    legend_elems = []\n",
    "    text_parts = []\n",
    "    for name, df in submissions.items():\n",
    "        s1, s2 = df[col1].values, df[col2].values\n",
    "        c = color_map_ct.get(name, 'gray')\n",
    "        ax.scatter(s1, s2, s=4, alpha=0.12, c=c, label=name)\n",
    "        rho_val, _ = stats.spearmanr(s1, s2)\n",
    "        text_parts.append(f\"{name} $\\\\rho$={rho_val:.3f}\")\n",
    "        legend_elems.append(Line2D([0], [0], marker='o', color='w', markerfacecolor=c,\n",
    "                                   markersize=6, label=name))\n",
    "\n",
    "    ax.text(0.03, 0.97, '\\n'.join(text_parts), transform=ax.transAxes, fontsize=9, va='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    ax.set_xlabel(TARGET_LABELS[k1])\n",
    "    ax.set_ylabel(TARGET_LABELS[k2])\n",
    "    ax.set_title(f'{TARGET_LABELS[k1]} vs {TARGET_LABELS[k2]}', fontsize=10)\n",
    "    ax.legend(handles=legend_elems, fontsize=8, loc='lower right')\n",
    "\n",
    "plt.suptitle('Cross-Target Consistency', fontsize=13, fontweight='bold')\n",
    "plt.tight_layout(w_pad=2)\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'comparison_cross_target.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: results/comparison_cross_target.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e62b95",
   "metadata": {
    "id": "71e62b95"
   },
   "source": [
    "## 5. Summary and Recommendation\n",
    "\n",
    "Aggregate **prediction-quality metrics only** into a winner-per-criterion table. Practical considerations (compute cost, interpretability) are noted in prose but excluded from the scoring — they don't affect NDCG.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac4ca8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15ac4ca8",
    "outputId": "4934d6a3-fe6c-4065-ee04-2c66bbfb9054"
   },
   "outputs": [],
   "source": [
    "summary_rows = []\n",
    "\n",
    "# Criterion 1: IsPETase zero-shot (Conservation only — ESM unavailable)\n",
    "summary_rows.append({\n",
    "    'Criterion': 'IsPETase zero-shot (10 mutants)',\n",
    "    'Conservation': f'rho={rho:.3f} (direct)',\n",
    "    'ESM': 'N/A (IsPETase not in test set)',\n",
    "    'Winner': 'Conservation (only available)'\n",
    "})\n",
    "\n",
    "# Criterion 2: IsPETase ML proxy (FAIR — same protocol, same data)\n",
    "summary_rows.append({\n",
    "    'Criterion': 'IsPETase ML proxy (31 variants, LOOCV)',\n",
    "    'Conservation': f'rho={cons_ml_rho:.3f} ({X_cons.shape[1]} features)',\n",
    "    'ESM': f'rho={esm_rho:.3f} ({X_all.shape[1]} features)',\n",
    "    'Winner': 'ESM' if esm_rho > cons_ml_rho else 'Conservation'\n",
    "})\n",
    "\n",
    "# Criterion 3: WT/mutant separation (average Cohen's d)\n",
    "cons_d_avg = sep_df[sep_df['Approach'] == 'Conservation']['Cohen_d'].abs().mean()\n",
    "esm_names = [k for k in submissions if k != 'Conservation']\n",
    "if esm_names:\n",
    "    esm_d_parts = []\n",
    "    best_esm_d = 0\n",
    "    for en in esm_names:\n",
    "        d_avg = sep_df[sep_df['Approach'] == en]['Cohen_d'].abs().mean()\n",
    "        esm_d_parts.append(f'{en}: {d_avg:.3f}')\n",
    "        best_esm_d = max(best_esm_d, d_avg)\n",
    "    summary_rows.append({\n",
    "        'Criterion': 'WT/Mutant separation (avg |d|)',\n",
    "        'Conservation': f'{cons_d_avg:.3f}',\n",
    "        'ESM': ', '.join(esm_d_parts),\n",
    "        'Winner': 'Conservation' if cons_d_avg > best_esm_d else esm_names[np.argmax([\n",
    "            sep_df[sep_df['Approach'] == en]['Cohen_d'].abs().mean() for en in esm_names])]\n",
    "    })\n",
    "\n",
    "# Criterion 4: Score granularity (unique scores — critical for NDCG)\n",
    "cons_unique = gran_df[gran_df['Approach'] == 'Conservation']['Unique Scores'].mean()\n",
    "if esm_names:\n",
    "    esm_unique_parts = []\n",
    "    best_esm_unique = 0\n",
    "    for en in esm_names:\n",
    "        u = gran_df[gran_df['Approach'] == en]['Unique Scores'].mean()\n",
    "        esm_unique_parts.append(f'{en}: {u:.0f}')\n",
    "        best_esm_unique = max(best_esm_unique, u)\n",
    "    summary_rows.append({\n",
    "        'Criterion': 'Score granularity (avg unique scores)',\n",
    "        'Conservation': f'{cons_unique:.0f}',\n",
    "        'ESM': ', '.join(esm_unique_parts),\n",
    "        'Winner': 'Conservation' if cons_unique > best_esm_unique else 'ESM'\n",
    "    })\n",
    "\n",
    "# Criterion 5: Within-scaffold discrimination\n",
    "cons_within = gran_df[gran_df['Approach'] == 'Conservation']['Within-Scaffold Std'].mean()\n",
    "if esm_names:\n",
    "    esm_within_parts = []\n",
    "    best_esm_within = 0\n",
    "    for en in esm_names:\n",
    "        w = gran_df[gran_df['Approach'] == en]['Within-Scaffold Std'].mean()\n",
    "        esm_within_parts.append(f'{en}: {w:.4f}')\n",
    "        best_esm_within = max(best_esm_within, w)\n",
    "    summary_rows.append({\n",
    "        'Criterion': 'Within-scaffold discrimination (avg std)',\n",
    "        'Conservation': f'{cons_within:.4f}',\n",
    "        'ESM': ', '.join(esm_within_parts),\n",
    "        'Winner': 'Conservation' if cons_within > best_esm_within else 'ESM'\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame(summary_rows)\n",
    "print(\"=\" * 80)\n",
    "print(\"APPROACH COMPARISON SUMMARY (prediction-quality metrics only)\")\n",
    "print(\"=\" * 80)\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "# Count wins\n",
    "cons_wins = sum(1 for r in summary_rows if 'Conservation' in r['Winner'] and 'ESM' not in r['Winner'])\n",
    "esm_wins = sum(1 for r in summary_rows if 'ESM' in r['Winner'] and 'Conservation' not in r['Winner'])\n",
    "ties = len(summary_rows) - cons_wins - esm_wins\n",
    "\n",
    "print(f\"\\n--- Score: Conservation {cons_wins}, ESM {esm_wins}, N/A {ties} ---\\n\")\n",
    "\n",
    "if cons_wins > esm_wins:\n",
    "    rec = \"Conservation\"\n",
    "    reason = (\"Conservation scoring wins on more prediction-quality criteria. \"\n",
    "              \"Recommended as primary submission.\")\n",
    "elif esm_wins > cons_wins:\n",
    "    rec = \"ESM v5\"\n",
    "    reason = (\"ESM scoring wins on more prediction-quality criteria, particularly \"\n",
    "              \"score granularity and within-scaffold discrimination — both critical for NDCG. \"\n",
    "              \"Recommended as primary submission.\")\n",
    "else:\n",
    "    rec = \"Ensemble\"\n",
    "    reason = (\"Results are tied. The ensemble at the optimal alpha blends Conservation's \"\n",
    "              \"strong WT/mutant separation with ESM's fine-grained ranking. \"\n",
    "              \"Recommended as primary submission.\")\n",
    "\n",
    "print(f\"RECOMMENDATION: Submit **{rec}** as primary\")\n",
    "print(f\"Rationale: {reason}\")\n",
    "\n",
    "# Practical notes (not scored)\n",
    "print(\"\\n--- Practical Considerations (not scored) ---\")\n",
    "print(\"  Compute: Conservation (CPU, ~1 min) vs ESM (A100 GPU, ~30 min)\")\n",
    "print(\"  Interpretability: Conservation (per-position) vs ESM (log-likelihood)\")\n",
    "print(\"  These don't affect NDCG and are excluded from the comparison scoring.\")\n",
    "\n",
    "if esm_available:\n",
    "    print(f\"\\nEnsemble optimal alphas (Cohen's d x rank entropy):\")\n",
    "    for key, alpha in optimal_alphas.items():\n",
    "        print(f\"  {TARGET_LABELS[key]}: alpha = {alpha:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0khko7m45k6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0khko7m45k6",
    "outputId": "4d1f54e9-8da6-4779-8520-4b551cb228c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed files:\n",
      "(no changes)\n",
      "Nothing to commit.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Git commit & push results to GitHub\n",
    "# ============================================================\n",
    "import subprocess, os\n",
    "\n",
    "os.chdir(PROJECT_ROOT)\n",
    "\n",
    "# Git user config (required on Colab - no global config)\n",
    "subprocess.run(['git', 'config', 'user.email', 'fulopjoz@users.noreply.github.com'], check=True)\n",
    "subprocess.run(['git', 'config', 'user.name', 'fulopjoz'], check=True)\n",
    "\n",
    "# Check status\n",
    "result = subprocess.run(['git', 'status', '--short'], capture_output=True, text=True)\n",
    "print(\"Changed files:\")\n",
    "print(result.stdout if result.stdout.strip() else \"(no changes)\")\n",
    "\n",
    "if result.stdout.strip():\n",
    "    # Stage all changes\n",
    "    subprocess.run(['git', 'add', '-A'], check=True)\n",
    "\n",
    "    # Commit\n",
    "    msg = input(\"Commit message (or Enter for default): \").strip()\n",
    "    if not msg:\n",
    "        msg = \"Update results from Colab run\"\n",
    "    subprocess.run(['git', 'commit', '-m', msg], check=True)\n",
    "\n",
    "    # Push (needs auth for public repo write access)\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "        token = userdata.get(\"GITHUB_TOKEN\")\n",
    "        remote_url = f\"https://{token}@github.com/fulopjoz/pet-challenge-2025.git\"\n",
    "        subprocess.run(['git', 'remote', 'set-url', 'origin', remote_url], check=True)\n",
    "    except Exception:\n",
    "        print(\"No GITHUB_TOKEN in Colab secrets. Set it up for automatic push.\")\n",
    "        print(\"Manual alternative: !git push  (will prompt for credentials)\")\n",
    "\n",
    "    result = subprocess.run(['git', 'push'], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"Pushed successfully!\")\n",
    "    else:\n",
    "        print(f\"Push failed:\\n{result.stderr}\")\n",
    "else:\n",
    "    print(\"Nothing to commit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "p16bl81se3f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p16bl81se3f",
    "outputId": "fa4bfe87-ec02-40d7-fa96-1223867e9f6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Removing old backup...\n",
      "Copying to Google Drive...\n",
      "Backup complete: /content/drive/MyDrive/pet-challenge-2025-backup\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Backup to Google Drive\n",
    "# ============================================================\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    import shutil\n",
    "\n",
    "    drive.mount('/content/drive')\n",
    "    source_dir = PROJECT_ROOT\n",
    "    dest_dir = '/content/drive/MyDrive/pet-challenge-2025-backup'\n",
    "\n",
    "    if os.path.exists(dest_dir):\n",
    "        print(\"Removing old backup...\")\n",
    "        shutil.rmtree(dest_dir)\n",
    "\n",
    "    print(\"Copying to Google Drive...\")\n",
    "    shutil.copytree(source_dir, dest_dir)\n",
    "    print(f\"Backup complete: {dest_dir}\")\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    print(\"Not running on Colab - skipping Google Drive backup.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
